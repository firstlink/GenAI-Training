{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 6: Multi-Agent Orchestration\n",
    "\n",
    "**Duration**: 90 minutes  \n",
    "**Difficulty**: Advanced\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- üéØ Design multi-agent architectures\n",
    "- üéØ Implement router agents  \n",
    "- üéØ Build specialist agents\n",
    "- üéØ Orchestrate agent workflows\n",
    "- üéØ Handle agent-to-agent communication\n",
    "\n",
    "## üìö What You'll Build\n",
    "\n",
    "**SupportGenie v0.6**: Multi-Agent System\n",
    "\n",
    "Specialized agents:\n",
    "- **Router Agent**: Classifies and routes queries\n",
    "- **Support Agent**: General inquiries\n",
    "- **Technical Agent**: Technical issues\n",
    "- **Sales Agent**: Orders and billing\n",
    "- **Escalation Agent**: Complex cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai python-dotenv -q\n",
    "\n",
    "print(\"‚úÖ Packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set up API key\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"‚úÖ API key loaded from Colab secrets\")\n",
    "except:\n",
    "    from getpass import getpass\n",
    "    if 'OPENAI_API_KEY' not in os.environ:\n",
    "        os.environ['OPENAI_API_KEY'] = getpass('Enter your OpenAI API key: ')\n",
    "    print(\"‚úÖ API key loaded\")\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
    "\n",
    "print(\"\\nüöÄ Ready to build multi-agent systems!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Why Multi-Agent Systems?\n",
    "\n",
    "### Single Agent Limitations\n",
    "- Tries to do everything\n",
    "- Generic responses\n",
    "- Hard to maintain\n",
    "- Doesn't scale well\n",
    "\n",
    "### Multi-Agent Benefits\n",
    "- Specialized expertise\n",
    "- Better accuracy\n",
    "- Easier to maintain\n",
    "- Scalable architecture\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "Orchestrator Agent\n",
    "    ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚Üì        ‚Üì         ‚Üì          ‚Üì\n",
    "Support  Technical Sales  Escalation\n",
    "Agent    Agent     Agent  Agent\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Router Agent\n",
    "\n",
    "The router classifies queries and routes them to the right specialist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouterAgent:\n",
    "    \"\"\"Classifies queries and routes to specialists\"\"\"\n",
    "    \n",
    "    CLASSIFICATION_PROMPT = \"\"\"Classify the customer query into ONE category:\n",
    "    \n",
    "    Categories:\n",
    "    - \"support\": General inquiries, policies, how-to questions\n",
    "    - \"technical\": Product issues, troubleshooting, bugs\n",
    "    - \"sales\": Orders, billing, payments, pricing\n",
    "    - \"escalation\": Complaints, refunds, urgent issues, angry customers\n",
    "    \n",
    "    Return ONLY the category name, nothing else.\n",
    "    \n",
    "    Query: {query}\n",
    "    Category:\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = OpenAI()\n",
    "    \n",
    "    def classify(self, query: str) -> str:\n",
    "        \"\"\"Classify query and return agent type\"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": self.CLASSIFICATION_PROMPT.format(query=query)\n",
    "            }],\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        classification = response.choices[0].message.content.strip().lower()\n",
    "        \n",
    "        # Validate classification\n",
    "        valid_types = [\"support\", \"technical\", \"sales\", \"escalation\"]\n",
    "        if classification not in valid_types:\n",
    "            return \"support\"  # Default fallback\n",
    "        \n",
    "        return classification\n",
    "\n",
    "# Test router\n",
    "router = RouterAgent()\n",
    "\n",
    "test_queries = [\n",
    "    \"How do I reset my password?\",\n",
    "    \"My laptop won't turn on\",\n",
    "    \"I want to cancel my order\",\n",
    "    \"This is unacceptable! I demand a refund!\"\n",
    "]\n",
    "\n",
    "print(\"üîÄ Router Agent Classification:\\n\")\n",
    "for query in test_queries:\n",
    "    classification = router.classify(query)\n",
    "    print(f\"Query: \\\"{query}\\\"\")\n",
    "    print(f\"‚Üí Route to: {classification.upper()} agent\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Specialist Agents\n",
    "\n",
    "Each specialist has its own expertise and system message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAgent:\n",
    "    \"\"\"Base class for specialist agents\"\"\"\n",
    "    \n",
    "    def __init__(self, system_message: str):\n",
    "        self.client = OpenAI()\n",
    "        self.system_message = system_message\n",
    "    \n",
    "    def process(self, query: str, context: dict = None) -> dict:\n",
    "        \"\"\"Process query with agent's expertise\"\"\"\n",
    "        \n",
    "        # Build context string\n",
    "        context_str = \"\"\n",
    "        if context:\n",
    "            context_str = f\"\\n\\nContext: {json.dumps(context)}\"\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_message},\n",
    "            {\"role\": \"user\", \"content\": query + context_str}\n",
    "        ]\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"response\": response.choices[0].message.content,\n",
    "            \"agent_type\": self.__class__.__name__,\n",
    "            \"needs_escalation\": self._check_escalation(response.choices[0].message.content)\n",
    "        }\n",
    "    \n",
    "    def _check_escalation(self, response: str) -> bool:\n",
    "        \"\"\"Check if response indicates escalation needed\"\"\"\n",
    "        escalation_phrases = [\n",
    "            \"escalate\",\n",
    "            \"human agent\",\n",
    "            \"supervisor\",\n",
    "            \"cannot resolve\"\n",
    "        ]\n",
    "        return any(phrase in response.lower() for phrase in escalation_phrases)\n",
    "\n",
    "print(\"‚úÖ BaseAgent class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportAgent(BaseAgent):\n",
    "    \"\"\"Handles general support inquiries\"\"\"\n",
    "    \n",
    "    SYSTEM_MESSAGE = \"\"\"You are a customer support specialist.\n",
    "    \n",
    "    Your expertise:\n",
    "    - Policies and procedures\n",
    "    - Account questions\n",
    "    - General how-to guidance\n",
    "    - Navigation assistance\n",
    "    \n",
    "    Guidelines:\n",
    "    - Be friendly and patient\n",
    "    - Provide clear, step-by-step instructions\n",
    "    - Reference relevant policies\n",
    "    - Escalate if issue is technical or requires refund\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(self.SYSTEM_MESSAGE)\n",
    "\n",
    "\n",
    "class TechnicalAgent(BaseAgent):\n",
    "    \"\"\"Handles technical issues\"\"\"\n",
    "    \n",
    "    SYSTEM_MESSAGE = \"\"\"You are a technical support specialist.\n",
    "    \n",
    "    Your expertise:\n",
    "    - Troubleshooting product issues\n",
    "    - Software/hardware diagnostics\n",
    "    - Technical configuration\n",
    "    - Bug identification\n",
    "    \n",
    "    Guidelines:\n",
    "    - Ask diagnostic questions\n",
    "    - Provide step-by-step troubleshooting\n",
    "    - Be technical but clear\n",
    "    - Escalate if hardware replacement needed\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(self.SYSTEM_MESSAGE)\n",
    "\n",
    "\n",
    "class SalesAgent(BaseAgent):\n",
    "    \"\"\"Handles orders and billing\"\"\"\n",
    "    \n",
    "    SYSTEM_MESSAGE = \"\"\"You are a sales support specialist.\n",
    "    \n",
    "    Your expertise:\n",
    "    - Order management\n",
    "    - Billing and payments\n",
    "    - Pricing questions\n",
    "    - Product recommendations\n",
    "    \n",
    "    Guidelines:\n",
    "    - Be helpful and consultative\n",
    "    - Upsell when appropriate\n",
    "    - Process order changes\n",
    "    - Escalate refund requests\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(self.SYSTEM_MESSAGE)\n",
    "\n",
    "\n",
    "class EscalationAgent(BaseAgent):\n",
    "    \"\"\"Handles escalations and complex cases\"\"\"\n",
    "    \n",
    "    SYSTEM_MESSAGE = \"\"\"You are a senior support specialist.\n",
    "    \n",
    "    Your expertise:\n",
    "    - Complex issues\n",
    "    - Customer complaints\n",
    "    - Refund processing\n",
    "    - Policy exceptions\n",
    "    \n",
    "    Guidelines:\n",
    "    - Be empathetic and apologetic\n",
    "    - Take ownership of issues\n",
    "    - Offer solutions proactively\n",
    "    - Prioritize customer satisfaction\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(self.SYSTEM_MESSAGE)\n",
    "\n",
    "print(\"‚úÖ All specialist agents defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test specialist agents\n",
    "\n",
    "support_agent = SupportAgent()\n",
    "tech_agent = TechnicalAgent()\n",
    "sales_agent = SalesAgent()\n",
    "\n",
    "print(\"Testing Specialist Agents:\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test SupportAgent\n",
    "print(\"\\n1. SUPPORT AGENT\")\n",
    "result = support_agent.process(\"How do I reset my password?\")\n",
    "print(f\"Response: {result['response'][:200]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Test TechnicalAgent\n",
    "print(\"\\n2. TECHNICAL AGENT\")\n",
    "result = tech_agent.process(\"My laptop won't turn on\")\n",
    "print(f\"Response: {result['response'][:200]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Test SalesAgent\n",
    "print(\"\\n3. SALES AGENT\")\n",
    "result = sales_agent.process(\"Can I upgrade my order?\")\n",
    "print(f\"Response: {result['response'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Orchestrator Pattern\n",
    "\n",
    "The orchestrator coordinates all agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentOrchestrator:\n",
    "    \"\"\"Orchestrates multiple specialist agents\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.router = RouterAgent()\n",
    "        self.agents = {\n",
    "            \"support\": SupportAgent(),\n",
    "            \"technical\": TechnicalAgent(),\n",
    "            \"sales\": SalesAgent(),\n",
    "            \"escalation\": EscalationAgent()\n",
    "        }\n",
    "    \n",
    "    def handle_query(self, query: str, context: dict = None) -> dict:\n",
    "        \"\"\"Route query to appropriate agent\"\"\"\n",
    "        \n",
    "        # 1. Route to appropriate agent\n",
    "        agent_type = self.router.classify(query)\n",
    "        print(f\"üîÄ Routing to: {agent_type.upper()} agent\")\n",
    "        \n",
    "        # 2. Get specialist agent\n",
    "        agent = self.agents[agent_type]\n",
    "        \n",
    "        # 3. Execute with specialist\n",
    "        response = agent.process(query, context)\n",
    "        \n",
    "        # 4. Check if escalation needed\n",
    "        if response['needs_escalation'] and agent_type != \"escalation\":\n",
    "            print(\"‚¨ÜÔ∏è  Escalating to senior agent...\")\n",
    "            response = self.agents[\"escalation\"].process(query, context)\n",
    "        \n",
    "        return response\n",
    "\n",
    "print(\"‚úÖ AgentOrchestrator class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test orchestrator\n",
    "\n",
    "orchestrator = AgentOrchestrator()\n",
    "\n",
    "test_scenarios = [\n",
    "    \"How do I track my order?\",\n",
    "    \"My screen has a dead pixel\",\n",
    "    \"I want to cancel my subscription\",\n",
    "    \"This is ridiculous! I've been waiting for 2 weeks!\"\n",
    "]\n",
    "\n",
    "print(\"üé≠ Testing Multi-Agent Orchestration\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, query in enumerate(test_scenarios, 1):\n",
    "    print(f\"\\n{i}. Query: \\\"{query}\\\"\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    result = orchestrator.handle_query(query)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Response from {result['agent_type']}:\")\n",
    "    print(result['response'][:300] + \"...\")\n",
    "    print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Parallel Execution\n",
    "\n",
    "Run multiple agents simultaneously and synthesize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelWorkflow:\n",
    "    \"\"\"Execute multiple agents in parallel\"\"\"\n",
    "    \n",
    "    def __init__(self, agents: list):\n",
    "        self.agents = agents\n",
    "    \n",
    "    def execute_parallel(self, query: str) -> dict:\n",
    "        \"\"\"Run all agents in parallel and synthesize results\"\"\"\n",
    "        \n",
    "        print(f\"üîÑ Running {len(self.agents)} agents in parallel...\\n\")\n",
    "        \n",
    "        # Execute in parallel\n",
    "        with ThreadPoolExecutor(max_workers=len(self.agents)) as executor:\n",
    "            futures = [\n",
    "                executor.submit(agent.process, query) \n",
    "                for agent in self.agents\n",
    "            ]\n",
    "            results = [f.result() for f in futures]\n",
    "        \n",
    "        # Synthesize results\n",
    "        return self.synthesize(query, results)\n",
    "    \n",
    "    def synthesize(self, query: str, results: list) -> dict:\n",
    "        \"\"\"Combine multiple agent responses\"\"\"\n",
    "        \n",
    "        # Prepare synthesis prompt\n",
    "        responses_text = \"\\n\\n\".join([\n",
    "            f\"Agent {i+1} ({r['agent_type']}): {r['response']}\"\n",
    "            for i, r in enumerate(results)\n",
    "        ])\n",
    "        \n",
    "        synthesis_prompt = f\"\"\"Multiple agents provided responses to this query:\n",
    "        \n",
    "Query: {query}\n",
    "\n",
    "Responses:\n",
    "{responses_text}\n",
    "\n",
    "Synthesize the best answer by combining insights from all agents.\n",
    "Provide a single, comprehensive response.\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": synthesis_prompt}]\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"synthesized_response\": response.choices[0].message.content,\n",
    "            \"individual_responses\": results\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ ParallelWorkflow class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parallel execution\n",
    "\n",
    "# Use multiple agents for a complex query\n",
    "parallel_agents = [\n",
    "    SupportAgent(),\n",
    "    TechnicalAgent(),\n",
    "    SalesAgent()\n",
    "]\n",
    "\n",
    "workflow = ParallelWorkflow(parallel_agents)\n",
    "\n",
    "query = \"I received a defective laptop. What are my options?\"\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = workflow.execute_parallel(query)\n",
    "\n",
    "print(\"\\nüìä Individual Agent Responses:\")\n",
    "for i, resp in enumerate(result['individual_responses'], 1):\n",
    "    print(f\"\\n{i}. {resp['agent_type']}:\")\n",
    "    print(resp['response'][:200] + \"...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\n‚ú® Synthesized Response:\")\n",
    "print(result['synthesized_response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: SupportGenie v0.6 - Complete Multi-Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportGenieV6:\n",
    "    \"\"\"\n",
    "    SupportGenie Version 0.6\n",
    "    Multi-agent customer support system\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.setup_agents()\n",
    "    \n",
    "    def setup_agents(self):\n",
    "        \"\"\"Initialize all agents\"\"\"\n",
    "        self.router = RouterAgent()\n",
    "        self.support_agent = SupportAgent()\n",
    "        self.tech_agent = TechnicalAgent()\n",
    "        self.sales_agent = SalesAgent()\n",
    "        self.escalation_agent = EscalationAgent()\n",
    "    \n",
    "    def handle_query(self, query: str, customer_profile: dict = None) -> dict:\n",
    "        \"\"\"Handle customer query with multi-agent routing\"\"\"\n",
    "        \n",
    "        # Classify query\n",
    "        agent_type = self.router.classify(query)\n",
    "        \n",
    "        print(f\"  üîÄ Classified as: {agent_type.upper()}\")\n",
    "        \n",
    "        # Route to specialist\n",
    "        if agent_type == \"support\":\n",
    "            response = self.support_agent.process(query, customer_profile)\n",
    "        elif agent_type == \"technical\":\n",
    "            response = self.tech_agent.process(query, customer_profile)\n",
    "        elif agent_type == \"sales\":\n",
    "            response = self.sales_agent.process(query, customer_profile)\n",
    "        else:\n",
    "            response = self.escalation_agent.process(query, customer_profile)\n",
    "        \n",
    "        # Auto-escalate if needed\n",
    "        if response['needs_escalation'] and agent_type != \"escalation\":\n",
    "            print(f\"  ‚¨ÜÔ∏è  Auto-escalating to senior agent\")\n",
    "            response = self.escalation_agent.process(query, customer_profile)\n",
    "        \n",
    "        return response\n",
    "\n",
    "print(\"‚úÖ SupportGenie v0.6 class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SupportGenie v0.6\n",
    "\n",
    "genie = SupportGenieV6()\n",
    "\n",
    "customer_profile = {\n",
    "    \"name\": \"Sarah Johnson\",\n",
    "    \"tier\": \"Gold\",\n",
    "    \"total_orders\": 25\n",
    "}\n",
    "\n",
    "test_queries = [\n",
    "    \"What's your return policy?\",\n",
    "    \"My device keeps crashing when I open the app\",\n",
    "    \"I need to change my billing address\",\n",
    "    \"I've been trying to get help for 3 days! This is unacceptable!\"\n",
    "]\n",
    "\n",
    "print(\"ü§ñ SupportGenie v0.6 - Multi-Agent System\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n{i}. Customer: \\\"{query}\\\"\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    result = genie.handle_query(query, customer_profile)\n",
    "    \n",
    "    print(f\"\\n  Agent: {result['agent_type']}\")\n",
    "    print(f\"\\n  Response: {result['response'][:250]}...\")\n",
    "    print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Add Agent Voting\n",
    "\n",
    "Implement a system where multiple agents vote on the best response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "class VotingSystem:\n",
    "    \"\"\"\n",
    "    Multiple agents vote on best response\n",
    "    \"\"\"\n",
    "    # TODO: Implement voting logic\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Sequential Agent Chain\n",
    "\n",
    "Create a chain where agents pass results to each other sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "class SequentialWorkflow:\n",
    "    \"\"\"\n",
    "    Agents execute in sequence, passing results forward\n",
    "    \"\"\"\n",
    "    # TODO: Implement sequential execution\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Add Metrics Tracking\n",
    "\n",
    "Track which agents are used most frequently and their success rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "class AgentMetrics:\n",
    "    \"\"\"\n",
    "    Track agent usage and performance\n",
    "    \"\"\"\n",
    "    # TODO: Implement metrics tracking\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Session 6 Complete!\n",
    "\n",
    "### What You Learned:\n",
    "\n",
    "‚úÖ Multi-agent systems scale better  \n",
    "‚úÖ Router agents enable specialization  \n",
    "‚úÖ Orchestrators coordinate workflows  \n",
    "‚úÖ Agents can run sequentially or parallel  \n",
    "‚úÖ Specialization improves accuracy  \n",
    "‚úÖ SupportGenie now has specialized expertise!\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "In **Session 7: Evaluation & Testing**, you'll learn:\n",
    "- Creating test datasets\n",
    "- Automated evaluation frameworks\n",
    "- LLM-as-judge pattern\n",
    "- A/B testing different approaches\n",
    "- Monitoring and metrics\n",
    "\n",
    "---\n",
    "\n",
    "**Continue to**: [Session 7: Evaluation ‚Üí](07_Evaluation.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Session 2: Advanced Prompt Engineering\n\n**Duration**: 75 minutes\n\nLearn to write effective prompts that make SupportGenie significantly smarter!\n\n---"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Setup\n!pip install -q openai\nimport os\nfrom openai import OpenAI\n\ntry:\n    from google.colab import userdata\n    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\nexcept:\n    from getpass import getpass\n    os.environ['OPENAI_API_KEY'] = getpass('Enter OpenAI API key: ')\n\nclient = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\nprint('✅ Setup complete!')"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Part 1: Bad vs Good Prompts"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Bad prompt\nbad_prompt = 'Tell me about returns'\n\n# Good prompt\ngood_prompt = '''As a customer service agent, explain our 30-day product return policy.\nInclude eligibility requirements and the return process. Keep it under 100 words.'''\n\n# Compare\nfor prompt in [bad_prompt, good_prompt]:\n    response = client.chat.completions.create(\n        model='gpt-3.5-turbo',\n        messages=[{'role': 'user', 'content': prompt}],\n        max_tokens=150\n    )\n    print(f'Prompt: {prompt[:50]}...')\n    print(f'Response: {response.choices[0].message.content}\\n')\n    print('-'*70)"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Part 2: System Messages"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["system_message = '''You are SupportGenie, a customer support AI for TechStore.\n\nGuidelines:\n- Be professional and empathetic\n- Keep responses under 100 words\n- Always offer to escalate if needed\n- Cite policies when relevant\n\nResponse format:\n1. Acknowledge concern\n2. Provide solution\n3. Ask if they need more help'''\n\nmessages = [\n    {'role': 'system', 'content': system_message},\n    {'role': 'user', 'content': 'My order is late!'}\n]\n\nresponse = client.chat.completions.create(\n    model='gpt-3.5-turbo',\n    messages=messages\n)\n\nprint(response.choices[0].message.content)"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Part 3: Few-Shot Learning"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["few_shot_prompt = '''Extract name and email as JSON.\n\nExamples:\n\nText: \"My name is Alice Johnson, email alice@test.com\"\nOutput: {\"name\": \"Alice Johnson\", \"email\": \"alice@test.com\"}\n\nText: \"I'm Bob Lee (bob.lee@company.com)\"\nOutput: {\"name\": \"Bob Lee\", \"email\": \"bob.lee@company.com\"}\n\nNow extract from:\nText: \"Hi, I'm John Smith. Contact me at john@email.com\"\nOutput:'''\n\nresponse = client.chat.completions.create(\n    model='gpt-3.5-turbo',\n    messages=[{'role': 'user', 'content': few_shot_prompt}],\n    temperature=0\n)\n\nprint(response.choices[0].message.content)"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Part 4: Prompt Templates"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["class PromptTemplate:\n    def __init__(self, template, variables):\n        self.template = template\n        self.variables = variables\n    \n    def format(self, **kwargs):\n        missing = set(self.variables) - set(kwargs.keys())\n        if missing:\n            raise ValueError(f'Missing variables: {missing}')\n        return self.template.format(**kwargs)\n\n# Define template\nproduct_template = PromptTemplate(\n    template='''As a product expert for {company}, answer this question about {product}.\n\nQuestion: {question}\n\nKeep response under {max_words} words. Use {tone} tone.\n\nAnswer:''',\n    variables=['company', 'product', 'question', 'max_words', 'tone']\n)\n\n# Use it\nprompt = product_template.format(\n    company='TechStore',\n    product='iPhone 15 Pro',\n    question=\"What's the battery life?\",\n    max_words=50,\n    tone='professional'\n)\n\nprint(prompt)\nprint('\\n' + '='*70 + '\\n')\n\nresponse = client.chat.completions.create(\n    model='gpt-3.5-turbo',\n    messages=[{'role': 'user', 'content': prompt}]\n)\n\nprint(response.choices[0].message.content)"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Part 5: SupportGenie v0.2 - Enhanced"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# See full implementation in session markdown file\n\nprint('✅ Session 2 Complete!')\nprint('\\nNext: Session 3 (RAG Systems) - Already covered!')\nprint('Then: Session 4 (Function Calling)')"]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

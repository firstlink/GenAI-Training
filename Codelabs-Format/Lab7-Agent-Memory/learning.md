# ğŸ“š Lab 7: Agent Memory & Planning - Learning Material

> **Duration:** 40 minutes
> **Level:** Advanced
> **Prerequisites:** Lab 6 (AI Agents & Tool Calling)

---

## ğŸ¯ Learning Objectives

By the end of this module, you will understand:
- âœ“ The three types of agent memory (short-term, working, long-term)
- âœ“ How agents maintain conversation context
- âœ“ Working memory for task tracking
- âœ“ Long-term memory with vector databases
- âœ“ The ReAct (Reasoning + Acting) framework
- âœ“ Thought â†’ Action â†’ Observation loops
- âœ“ Task planning and decomposition
- âœ“ Self-reflection and error correction
- âœ“ When and why agents should plan

---

## ğŸ“– Table of Contents

1. [Understanding Agent Memory](#1-understanding-agent-memory)
2. [Short-Term Memory](#2-short-term-memory-conversation-history)
3. [Working Memory](#3-working-memory-task-context)
4. [Long-Term Memory](#4-long-term-memory-persistent-storage)
5. [The ReAct Framework](#5-the-react-framework)
6. [Agent Planning Strategies](#6-agent-planning-strategies)
7. [Self-Reflection & Error Correction](#7-self-reflection--error-correction)
8. [When to Use Memory & Planning](#8-when-to-use-memory--planning)

---

## 1. Understanding Agent Memory

### What is Agent Memory?

Agent memory allows AI systems to:
- **Remember** past interactions and context
- **Learn** from previous conversations
- **Maintain continuity** across sessions
- **Personalize** responses based on history
- **Improve** decision-making with experience

### The Three Types of Memory

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   AGENT MEMORY SYSTEM                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  1. SHORT-TERM MEMORY                               â”‚   â”‚
â”‚  â”‚  (Conversation History)                             â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  â€¢ Current conversation messages                    â”‚   â”‚
â”‚  â”‚  â€¢ Recent tool calls and results                    â”‚   â”‚
â”‚  â”‚  â€¢ Immediate context                                â”‚   â”‚
â”‚  â”‚  â€¢ Duration: Current session                        â”‚   â”‚
â”‚  â”‚  â€¢ Storage: Message array in memory                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  2. WORKING MEMORY                                  â”‚   â”‚
â”‚  â”‚  (Task Context)                                     â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  â€¢ Variables and state for current task             â”‚   â”‚
â”‚  â”‚  â€¢ Intermediate calculation results                 â”‚   â”‚
â”‚  â”‚  â€¢ Task progress tracking                           â”‚   â”‚
â”‚  â”‚  â€¢ Duration: Until task complete                    â”‚   â”‚
â”‚  â”‚  â€¢ Storage: In-memory dictionaries/objects          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  3. LONG-TERM MEMORY                                â”‚   â”‚
â”‚  â”‚  (Persistent Storage)                               â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  â€¢ User preferences and facts                       â”‚   â”‚
â”‚  â”‚  â€¢ Past conversations (summarized)                  â”‚   â”‚
â”‚  â”‚  â€¢ Learned knowledge and patterns                   â”‚   â”‚
â”‚  â”‚  â€¢ Duration: Indefinite (persists across sessions)  â”‚   â”‚
â”‚  â”‚  â€¢ Storage: Vector database (ChromaDB, Pinecone)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Human Memory Analogy

Think of it like human memory:

| Memory Type | Human Equivalent | Agent Example |
|------------|------------------|---------------|
| **Short-term** | What you just heard in conversation | Last 10-20 messages in chat |
| **Working** | Notes you're taking during a task | Variables like `total_price = 150` |
| **Long-term** | Facts you remember about a person | "User prefers Python over Java" |

---

## 2. Short-Term Memory (Conversation History)

### What is Short-Term Memory?

Short-term memory is the **conversation history** - the messages exchanged between user and agent in the current session.

### How It Works

```python
messages = [
    {"role": "system", "content": "You are a helpful assistant"},
    {"role": "user", "content": "Hi, I'm Alice"},
    {"role": "assistant", "content": "Hello Alice! Nice to meet you."},
    {"role": "user", "content": "What's my name?"},
    {"role": "assistant", "content": "Your name is Alice!"}
]
```

The agent can answer "What's my name?" because it **remembers** the conversation history.

### Memory Management

**Problem:** Conversations can get very long
**Solution:** Trim old messages, keeping only recent context

```python
# Keep only last 20 messages (plus system message)
max_messages = 20
if len(messages) > max_messages:
    system_msgs = [m for m in messages if m["role"] == "system"]
    recent_msgs = [m for m in messages if m["role"] != "system"][-max_messages:]
    messages = system_msgs + recent_msgs
```

### Why Trim?

1. **Token limits:** APIs have maximum context length (e.g., 128K tokens)
2. **Cost:** Fewer tokens = lower API costs
3. **Focus:** Too much context can confuse the model
4. **Performance:** Smaller context = faster responses

### Example: Agent Without Memory vs With Memory

**Without Memory:**
```
User: Hi, I'm Bob
Agent: Hello! How can I help you?

User: What's my name?
Agent: I don't know your name. You haven't told me.
```

**With Memory:**
```
User: Hi, I'm Bob
Agent: Hello Bob! How can I help you?

User: What's my name?
Agent: Your name is Bob!
```

---

## 3. Working Memory (Task Context)

### What is Working Memory?

Working memory stores **task-specific information** while the agent works on a problem. It's like a notepad for the current task.

### Use Cases

1. **Multi-step calculations**
   - Store intermediate results
   - Track progress through steps

2. **Data collection tasks**
   - Accumulate information from multiple sources
   - Build up a complete answer

3. **Stateful workflows**
   - Track which steps are complete
   - Know what to do next

### Working Memory Structure

```python
working_memory = {
    "task_name": "Calculate compound interest",
    "status": "in_progress",  # idle, in_progress, completed, failed
    "variables": {
        "principal": 1000,
        "rate": 0.05,
        "time": 3,
        "amount": 1157.63  # Calculated
    },
    "steps_completed": [
        "Get input values",
        "Calculate final amount"
    ],
    "current_step": "Calculate interest gained",
    "intermediate_results": [
        {"step": 1, "result": 1157.63, "description": "Final amount"}
    ]
}
```

### Example: Multi-Step Math Problem

**Task:** "Calculate 20% of 500, store it as 'tax', then add it to 500"

**Working Memory Progression:**

```
Step 1:
working_memory.variables = {}

Step 2: Calculate 20% of 500
working_memory.variables = {"tax": 100}

Step 3: Add to 500
working_memory.variables = {
    "tax": 100,
    "total": 600
}

Task complete!
```

### Benefits of Working Memory

âœ“ **Track progress** through complex tasks
âœ“ **Store intermediate results** for later use
âœ“ **Resume tasks** if interrupted
âœ“ **Debug issues** by inspecting state
âœ“ **Avoid redundant calculations** by caching results

---

## 4. Long-Term Memory (Persistent Storage)

### What is Long-Term Memory?

Long-term memory **persists across sessions** using a database. It stores facts, preferences, and knowledge indefinitely.

### Storage: Vector Databases

Long-term memory uses **vector databases** (like ChromaDB) to store information as:
- **Document:** The actual text/fact
- **Embedding:** 384-dimensional vector representing semantic meaning
- **Metadata:** Additional info (type, timestamp, category)

### How Vector Memory Works

```
1. STORE a fact:
   "User prefers Python over JavaScript"
   â†“
   Convert to embedding (vector)
   â†“
   Store in ChromaDB

2. RETRIEVE relevant facts:
   Query: "What languages does user like?"
   â†“
   Convert query to embedding
   â†“
   Find similar embeddings (semantic search)
   â†“
   Return: "User prefers Python over JavaScript"
```

### Types of Long-Term Memories

```python
memory_types = {
    "user_fact": "User's name is Alice",
    "user_preference": "User likes detailed explanations",
    "user_skill": "User is proficient in Python",
    "conversation_summary": "Discussed machine learning basics on 2024-01-15",
    "learned_knowledge": "User works as a data scientist at TechCorp"
}
```

### Retrieval Process

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LONG-TERM MEMORY RETRIEVAL                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                           â”‚
â”‚  User Query: "What do I do for work?"                     â”‚
â”‚       â†“                                                   â”‚
â”‚  Convert to embedding [0.23, -0.41, 0.56, ...]           â”‚
â”‚       â†“                                                   â”‚
â”‚  Search vector database for similar embeddings           â”‚
â”‚       â†“                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Top 3 Matches (by similarity):                 â”‚     â”‚
â”‚  â”‚  1. "User works as data scientist" (0.92)       â”‚     â”‚
â”‚  â”‚  2. "User is skilled in Python" (0.76)          â”‚     â”‚
â”‚  â”‚  3. "User joined TechCorp in 2023" (0.71)       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚       â†“                                                   â”‚
â”‚  Filter by relevance threshold (> 0.70)                  â”‚
â”‚       â†“                                                   â”‚
â”‚  Return matched memories to agent                        â”‚
â”‚       â†“                                                   â”‚
â”‚  Agent uses memories to generate answer:                 â”‚
â”‚  "You work as a data scientist at TechCorp!"            â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Memory Lifecycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STORE      â”‚  User: "I prefer dark mode"
â”‚            â”‚  â†’ Store: "User prefers dark mode"
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RETRIEVE   â”‚  User: "What do I prefer?"
â”‚            â”‚  â†’ Retrieve: "User prefers dark mode"
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UPDATE     â”‚  User: "Actually, I like light mode now"
â”‚            â”‚  â†’ Update memory or store new version
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FORGET     â”‚  Old memories decay or are deleted
â”‚            â”‚  (optional - can implement memory decay)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example: Agent with Full Memory System

```
Session 1:
User: "Hi, I'm Alice and I love Python"
Agent: *Stores in long-term memory*

[Agent shuts down, restart later]

Session 2 (days later):
User: "What do you know about me?"
Agent: *Retrieves from long-term memory*
      "Your name is Alice and you love Python programming!"
```

---

## 5. The ReAct Framework

### What is ReAct?

**ReAct** = **Rea**soning + **Act**ing

A framework where agents **show their thinking** before taking actions, making their decision-making transparent and debuggable.

### Traditional Agent vs ReAct Agent

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TRADITIONAL AGENT (Black Box)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  User: "What is 15% of 340?"                            â”‚
â”‚       â†“                                                  â”‚
â”‚  [Tool: calculator("340 * 0.15")]  â† Hidden reasoning   â”‚
â”‚       â†“                                                  â”‚
â”‚  Agent: "15% of 340 is 51"                              â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REACT AGENT (Transparent)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  User: "What is 15% of 340?"                            â”‚
â”‚       â†“                                                  â”‚
â”‚  ğŸ’­ THOUGHT:                                            â”‚
â”‚  "I need to calculate 15% of 340. This requires         â”‚
â”‚   multiplication: 340 Ã— 0.15"                           â”‚
â”‚       â†“                                                  â”‚
â”‚  ğŸ”§ ACTION: calculator("340 * 0.15")                    â”‚
â”‚       â†“                                                  â”‚
â”‚  ğŸ‘ï¸ OBSERVATION: Result = 51.0                         â”‚
â”‚       â†“                                                  â”‚
â”‚  ğŸ’­ THOUGHT:                                            â”‚
â”‚  "The calculation is complete. I have the answer."      â”‚
â”‚       â†“                                                  â”‚
â”‚  Agent: "15% of 340 is 51"                              â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The ReAct Loop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    REACT CYCLE                         â”‚
â”‚                                                        â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚      â”‚   1. THOUGHT         â”‚                         â”‚
â”‚      â”‚   (Reasoning)        â”‚                         â”‚
â”‚      â”‚                      â”‚                         â”‚
â”‚      â”‚  "What should I do?" â”‚                         â”‚
â”‚      â”‚  "What info do I     â”‚                         â”‚
â”‚      â”‚   need?"             â”‚                         â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                 â”‚                                      â”‚
â”‚                 â†“                                      â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚      â”‚   2. ACTION          â”‚                         â”‚
â”‚      â”‚   (Tool Use)         â”‚                         â”‚
â”‚      â”‚                      â”‚                         â”‚
â”‚      â”‚  Call specific tool  â”‚                         â”‚
â”‚      â”‚  with parameters     â”‚                         â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                 â”‚                                      â”‚
â”‚                 â†“                                      â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚      â”‚   3. OBSERVATION     â”‚                         â”‚
â”‚      â”‚   (Result)           â”‚                         â”‚
â”‚      â”‚                      â”‚                         â”‚
â”‚      â”‚  "What did I get?"   â”‚                         â”‚
â”‚      â”‚  "Was it successful?"â”‚                         â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                 â”‚                                      â”‚
â”‚                 â†“                                      â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚      â”‚   4. DECISION        â”‚                         â”‚
â”‚      â”‚                      â”‚                         â”‚
â”‚      â”‚  Done? â†’ Answer      â”‚                         â”‚
â”‚      â”‚  Not done? â†’ THOUGHT â”‚â”€â”€â”€â”€â”€â”                  â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚                  â”‚
â”‚                                    â”‚                  â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                    â”‚                                  â”‚
â”‚                    â””â”€â†’ Loop back to THOUGHT           â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ReAct Example: Research Task

**Task:** "Find information about Python and calculate how old it is"

```
ITERATION 1:
ğŸ’­ THOUGHT: "I need to find when Python was created first"
ğŸ”§ ACTION: search_info("Python programming language")
ğŸ‘ï¸ OBSERVATION: "Python created by Guido van Rossum in 1991"

ITERATION 2:
ğŸ’­ THOUGHT: "Now I know it was created in 1991. Current year is 2024.
              I need to calculate: 2024 - 1991"
ğŸ”§ ACTION: calculator("2024 - 1991")
ğŸ‘ï¸ OBSERVATION: Result = 33

ITERATION 3:
ğŸ’­ THOUGHT: "I have all the information needed. Python is 33 years old."
FINAL ANSWER: "Python was created in 1991, making it 33 years old."
```

### Benefits of ReAct

âœ“ **Transparency:** See exactly why agent made each decision
âœ“ **Debuggability:** Identify where reasoning went wrong
âœ“ **Trustworthiness:** Users can verify the logic
âœ“ **Error correction:** Agent can catch its own mistakes
âœ“ **Explainability:** Understand the full reasoning chain

---

## 6. Agent Planning Strategies

### What is Planning?

Planning is when an agent **creates a strategy** before executing, rather than deciding step-by-step.

### Plan-Then-Execute Pattern

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REACTIVE (No Planning)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  User: "Research Paris and calculate travel budget"    â”‚
â”‚     â†“                                                   â”‚
â”‚  Act â†’ Observe â†’ Act â†’ Observe â†’ Act â†’ Observe         â”‚
â”‚  (Figures out what to do as it goes)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PLAN-THEN-EXECUTE                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  User: "Research Paris and calculate travel budget"    â”‚
â”‚     â†“                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ PLANNING PHASE:                              â”‚      â”‚
â”‚  â”‚ 1. Search for Paris info                     â”‚      â”‚
â”‚  â”‚ 2. Search for flight prices                  â”‚      â”‚
â”‚  â”‚ 3. Search for hotel prices                   â”‚      â”‚
â”‚  â”‚ 4. Calculate total: flights + hotels + food  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚     â†“                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ EXECUTION PHASE:                             â”‚      â”‚
â”‚  â”‚ Execute steps 1-4 in order                   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Types of Planning

#### 1. Linear Planning
Sequential steps, one after another:
```
1. Do A
2. Do B
3. Do C
4. Done
```

#### 2. Hierarchical Planning
Break complex tasks into subtasks:
```
Main Task: Plan vacation
â”œâ”€â”€ Subtask 1: Research destination
â”‚   â”œâ”€â”€ Find weather info
â”‚   â”œâ”€â”€ Find attractions
â”‚   â””â”€â”€ Read reviews
â”œâ”€â”€ Subtask 2: Book travel
â”‚   â”œâ”€â”€ Book flights
â”‚   â””â”€â”€ Book hotel
â””â”€â”€ Subtask 3: Create itinerary
    â”œâ”€â”€ Day 1 plan
    â”œâ”€â”€ Day 2 plan
    â””â”€â”€ Day 3 plan
```

#### 3. Conditional Planning
Plans with if/then branches:
```
1. Check budget
2. If budget > $2000:
     - Book premium flight
   Else:
     - Book economy flight
3. Search hotels in budget range
4. Book hotel
```

### When to Use Planning

| Use Planning When... | Skip Planning When... |
|---------------------|----------------------|
| âœ“ Task is complex with many steps | âœ— Task is simple (1-2 steps) |
| âœ“ Steps have dependencies | âœ— Steps are independent |
| âœ“ Need to optimize order | âœ— Order doesn't matter |
| âœ“ Resources are constrained | âœ— No constraints |
| âœ“ Explaining approach is valuable | âœ— Speed is critical |

### Example: Travel Planning Agent

```
PLANNING PHASE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Goal: Plan a 3-day trip to Paris                â”‚
â”‚                                                  â”‚
â”‚ Plan:                                            â”‚
â”‚ 1. Search Paris weather for travel dates        â”‚
â”‚ 2. Find top 5 attractions                       â”‚
â”‚ 3. Search round-trip flights                    â”‚
â”‚ 4. Search hotels near attractions               â”‚
â”‚ 5. Calculate total budget                       â”‚
â”‚ 6. Create day-by-day itinerary                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

EXECUTION PHASE:
Step 1: âœ… Weather found: 18Â°C, partly cloudy
Step 2: âœ… Attractions: Eiffel Tower, Louvre, Notre Dame...
Step 3: âœ… Flight: $650 round-trip
Step 4: âœ… Hotel: $120/night Ã— 3 = $360
Step 5: âœ… Total budget: $1,210 (flights + hotel + food estimate)
Step 6: âœ… Itinerary created

RESULT: Complete 3-day Paris trip plan with budget
```

---

## 7. Self-Reflection & Error Correction

### What is Self-Reflection?

Self-reflection is when an agent **evaluates its own progress** and adjusts course if needed.

### Reflection Points

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AGENT WORKFLOW WITH REFLECTION                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                       â”‚
â”‚  Action 1: Search for information                    â”‚
â”‚  Action 2: Calculate result                          â”‚
â”‚  Action 3: Search more details                       â”‚
â”‚      â†“                                                â”‚
â”‚  ğŸ¤” REFLECTION POINT                                 â”‚
â”‚  "Am I making progress toward the goal?"             â”‚
â”‚  "Did any actions fail?"                             â”‚
â”‚  "Should I change my approach?"                      â”‚
â”‚      â†“                                                â”‚
â”‚  Decision: Adjust approach / Continue / Give up      â”‚
â”‚      â†“                                                â”‚
â”‚  Action 4: Based on reflection...                    â”‚
â”‚                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Reflection Questions

An agent should ask itself:

1. **Progress Check:**
   - "Am I closer to the goal than before?"
   - "Is this approach working?"

2. **Error Detection:**
   - "Did any tools return errors?"
   - "Are results what I expected?"

3. **Resource Check:**
   - "How many attempts have I made?"
   - "Am I using tools efficiently?"

4. **Strategy Evaluation:**
   - "Is there a better way to solve this?"
   - "Should I try a different tool?"

### Example: Agent with Self-Reflection

```
Task: "Find the population of Paris and calculate persons per square km"

ATTEMPT 1:
Action: search("Paris")
Result: "Paris is the capital of France..."
ğŸ¤” REFLECTION: "I got general info, but no population number.
                I need to search more specifically."

ATTEMPT 2:
Action: search("Paris population 2024")
Result: "Paris population: approximately 2.2 million"
ğŸ¤” REFLECTION: "Good! I have population. Now I need area."

ATTEMPT 3:
Action: search("Paris area square kilometers")
Result: "Paris area: 105.4 kmÂ²"
ğŸ¤” REFLECTION: "Perfect! I have both numbers. Now calculate."

ATTEMPT 4:
Action: calculator("2200000 / 105.4")
Result: 20,872
ğŸ¤” REFLECTION: "Calculation complete. I have the answer!"

Final: "Paris has about 20,872 persons per square km"
```

### Dynamic Replanning

When reflection reveals a problem, the agent can **replan**:

```
ORIGINAL PLAN:
1. Search for flight prices
2. Search for hotel prices
3. Calculate total budget

EXECUTION:
Step 1: âœ… Flight prices found
Step 2: âŒ Hotel API returned error
ğŸ¤” REFLECTION: "Hotel search failed. I need a new approach."

NEW PLAN (Replanning):
1. âœ… (Already done) Flight prices
2. Try alternative hotel search method
3. If that fails, use estimated hotel costs
4. Calculate budget with available data

EXECUTION CONTINUES:
Step 2b: âœ… Alternative search succeeded
Step 3: âœ… Budget calculated
```

### Benefits of Self-Reflection

âœ“ **Adaptive:** Changes approach when stuck
âœ“ **Robust:** Recovers from errors automatically
âœ“ **Efficient:** Avoids repeating failed approaches
âœ“ **Transparent:** Shows reasoning for changes
âœ“ **Intelligent:** Learns what works and what doesn't

---

## 8. When to Use Memory & Planning

### Memory Usage Decision Tree

```
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ Does agent need  â”‚
                 â”‚ to remember info?â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                            â”‚
         â”Œâ”€â”€â–¼â”€â”€â”                     â”Œâ”€â”€â–¼â”€â”€â”
         â”‚ YES â”‚                     â”‚ NO  â”‚
         â””â”€â”€â”¬â”€â”€â”˜                     â””â”€â”€â”¬â”€â”€â”˜
            â”‚                            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
    â”‚ For how long?  â”‚            Use stateless
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜             agent
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                          â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚Current â”‚              â”‚ Across    â”‚
â”‚session â”‚              â”‚ sessions  â”‚
â”‚ only   â”‚              â”‚           â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚                         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Short-term  â”‚          â”‚Long-term      â”‚
â”‚memory      â”‚          â”‚memory         â”‚
â”‚(messages)  â”‚          â”‚(vector DB)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Planning Usage Decision Tree

```
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ Is task complex? â”‚
                 â”‚ (>3 steps)       â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                            â”‚
         â”Œâ”€â”€â–¼â”€â”€â”                     â”Œâ”€â”€â–¼â”€â”€â”
         â”‚ YES â”‚                     â”‚ NO  â”‚
         â””â”€â”€â”¬â”€â”€â”˜                     â””â”€â”€â”¬â”€â”€â”˜
            â”‚                            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”             Use reactive
    â”‚ Dependencies?  â”‚              (no planning)
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                          â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Steps   â”‚              â”‚Steps are     â”‚
â”‚depend  â”‚              â”‚independent   â”‚
â”‚on each â”‚              â”‚              â”‚
â”‚other   â”‚              â”‚              â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Use           â”‚        â”‚Parallel or    â”‚
â”‚sequential    â”‚        â”‚simple         â”‚
â”‚planning      â”‚        â”‚planning       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Best Practices

#### Memory Best Practices

âœ“ **Trim aggressively:** Keep only essential context
âœ“ **Categorize:** Tag memories by type (fact, preference, skill)
âœ“ **Update regularly:** Replace outdated information
âœ“ **Filter by relevance:** Don't retrieve irrelevant memories
âœ“ **Summarize periodically:** Condense long conversations

#### Planning Best Practices

âœ“ **Plan at the right level:** Not too detailed, not too vague
âœ“ **Allow flexibility:** Plans can change during execution
âœ“ **Set checkpoints:** Validate progress at key points
âœ“ **Time-box planning:** Don't spend too long planning
âœ“ **Learn from failures:** Improve planning from mistakes

### Real-World Applications

| Application | Memory Needed | Planning Needed |
|------------|---------------|-----------------|
| **Chat** bot | Short-term (conversation) | No planning |
| **Research Agent** | Long-term (sources) + Working (findings) | Yes - search strategy |
| **Customer Support** | Long-term (user history) + Short-term | Conditional planning |
| **Personal Assistant** | All three types | Yes - task scheduling |
| **Code Generator** | Working (current code structure) | Yes - implementation plan |
| **Data Analyzer** | Working (analysis results) | Yes - analysis steps |

---

## ğŸ“ Summary

### Key Concepts Recap

**Memory Systems:**
- âœ“ **Short-term:** Conversation history (messages)
- âœ“ **Working:** Task variables and state
- âœ“ **Long-term:** Persistent facts (vector DB)

**ReAct Framework:**
- âœ“ **Thought:** Reasoning about what to do
- âœ“ **Action:** Using tools
- âœ“ **Observation:** Analyzing results
- âœ“ **Loop:** Repeat until task complete

**Planning:**
- âœ“ **Plan-then-execute:** Create strategy first
- âœ“ **Dynamic replanning:** Adapt when things fail
- âœ“ **Self-reflection:** Evaluate progress periodically

### Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COMPLETE AGENT ARCHITECTURE                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚  Short-term  â”‚â—„â”€â”€â”€â”€â–ºâ”‚   Working    â”‚               â”‚
â”‚  â”‚   Memory     â”‚      â”‚   Memory     â”‚               â”‚
â”‚  â”‚ (messages)   â”‚      â”‚ (task state) â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚         â”‚                      â”‚                       â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                    â”‚                                   â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                            â”‚
â”‚              â”‚           â”‚                            â”‚
â”‚              â”‚  REACT    â”‚                            â”‚
â”‚              â”‚  AGENT    â”‚                            â”‚
â”‚              â”‚           â”‚                            â”‚
â”‚              â”‚  â€¢ Think  â”‚                            â”‚
â”‚              â”‚  â€¢ Act    â”‚                            â”‚
â”‚              â”‚  â€¢ Observeâ”‚                            â”‚
â”‚              â”‚  â€¢ Reflectâ”‚                            â”‚
â”‚              â”‚           â”‚                            â”‚
â”‚              â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                    â”‚                                   â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚         â”‚                      â”‚                      â”‚
â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚    â”‚ Long-termâ”‚         â”‚  Planning  â”‚               â”‚
â”‚    â”‚  Memory  â”‚         â”‚   System   â”‚               â”‚
â”‚    â”‚(Vector DB)â”‚         â”‚            â”‚               â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Knowledge Check

Test your understanding with these questions:

### Question 1: Memory Types
Which type of memory would you use to store "User prefers dark mode" across sessions?

<details>
<summary>Click to see answer</summary>

**Answer:** Long-term memory (vector database)

**Explanation:** This is a persistent preference that should be remembered even after the session ends, making it perfect for long-term memory storage.

</details>

### Question 2: ReAct Benefits
What is the main advantage of the ReAct framework over traditional agents?

<details>
<summary>Click to see answer</summary>

**Answer:** Transparency and debuggability

**Explanation:** ReAct makes the agent's reasoning visible through explicit "Thought" steps, allowing developers to see exactly why the agent made each decision. This makes it much easier to debug and understand agent behavior.

</details>

### Question 3: When to Plan
When should an agent create a plan before executing?

<details>
<summary>Click to see answer</summary>

**Answer:** When the task is complex (>3 steps) and steps have dependencies

**Explanation:** Planning is most valuable for complex tasks where the order of operations matters and where understanding the full strategy upfront leads to better outcomes.

</details>

### Question 4: Working Memory
What should be stored in working memory during a multi-step calculation?

<details>
<summary>Click to see answer</summary>

**Answer:** Intermediate results and variables for the current task

**Explanation:** Working memory is perfect for storing temporary values like "tax = 100" or "subtotal = 500" that are only needed for the duration of the current task.

</details>

### Question 5: Self-Reflection
How does self-reflection improve agent performance?

<details>
<summary>Click to see answer</summary>

**Answer:** It allows the agent to detect errors, evaluate progress, and adjust its approach when needed

**Explanation:** Self-reflection acts like a checkpoint system where the agent periodically asks "Is this working?" and can change strategy if the current approach isn't making progress.

</details>

---

## ğŸš€ Ready for Hands-On Practice!

You now understand:
- âœ… The three types of agent memory
- âœ… How memory systems work together
- âœ… The ReAct framework for transparent reasoning
- âœ… Planning strategies and when to use them
- âœ… Self-reflection for error correction

**Next Step:** Move to the hands-on lab to build these systems yourself!

[â†’ Continue to Hands-On Lab](lab.md)

---

**Learning Module Complete!** ğŸ‰
Time to put theory into practice with real code examples.

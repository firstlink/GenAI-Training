{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Agent Memory & Planning\n",
    "\n",
    "**Duration**: 100-130 minutes  \n",
    "**Level**: Advanced  \n",
    "**Prerequisites**: Lab 6 completed\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this lab, you'll build increasingly sophisticated agents with memory systems and planning capabilities.\n",
    "\n",
    "### What You'll Build:\n",
    "\n",
    "1. **Memory Agent** - Agent with short-term, working, and long-term memory\n",
    "2. **ReAct Agent** - Agent using Thought â†’ Action â†’ Observation loop\n",
    "3. **Planning Agent** - Agent that plans before executing\n",
    "4. **Reflective Agent** - Agent with self-reflection and error correction\n",
    "5. **IntelliAgent v1.0** - Complete agent with memory + planning (Capstone)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Implement short-term memory (conversation history)\n",
    "- Build working memory for task tracking\n",
    "- Create long-term memory with vector databases\n",
    "- Implement the ReAct framework\n",
    "- Build planning agents that create strategies\n",
    "- Add self-reflection for error correction\n",
    "- Combine memory and planning in production agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai anthropic python-dotenv chromadb sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional, Callable\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API keys\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(f\"OpenAI API Key present: {bool(openai_key)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test setup\n",
    "from openai import OpenAI\n",
    "import chromadb\n",
    "\n",
    "# Test OpenAI connection\n",
    "try:\n",
    "    client = OpenAI(api_key=openai_key)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Hi\"}],\n",
    "        max_tokens=10\n",
    "    )\n",
    "    print(\"âœ“ OpenAI API working\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— OpenAI API error: {e}\")\n",
    "\n",
    "# Test ChromaDB\n",
    "try:\n",
    "    chroma_client = chromadb.Client()\n",
    "    print(\"âœ“ ChromaDB working\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— ChromaDB error: {e}\")\n",
    "\n",
    "print(\"\\nâœ… Setup complete! Ready for exercises.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Agent with Memory Systems\n",
    "\n",
    "Build an agent with short-term, working, and long-term memory.\n",
    "\n",
    "### Part A: Short-Term Memory\n",
    "\n",
    "Short-term memory manages conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short-Term Memory Implementation\n",
    "\n",
    "class ShortTermMemory:\n",
    "    \"\"\"Manages conversation history\"\"\"\n",
    "\n",
    "    def __init__(self, max_messages: int = 20):\n",
    "        self.messages: List[Dict] = []\n",
    "        self.max_messages = max_messages\n",
    "\n",
    "    def add_system_message(self, content: str):\n",
    "        \"\"\"Add system message at the beginning\"\"\"\n",
    "        self.messages.insert(0, {\"role\": \"system\", \"content\": content})\n",
    "\n",
    "    def add_user_message(self, content: str):\n",
    "        \"\"\"Add user message\"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": content})\n",
    "        self._trim_if_needed()\n",
    "\n",
    "    def add_assistant_message(self, content: str):\n",
    "        \"\"\"Add assistant message\"\"\"\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "        self._trim_if_needed()\n",
    "\n",
    "    def _trim_if_needed(self):\n",
    "        \"\"\"Keep only recent messages + system message\"\"\"\n",
    "        system_msgs = [m for m in self.messages if m[\"role\"] == \"system\"]\n",
    "        other_msgs = [m for m in self.messages if m[\"role\"] != \"system\"]\n",
    "\n",
    "        if len(other_msgs) > self.max_messages:\n",
    "            other_msgs = other_msgs[-self.max_messages:]\n",
    "\n",
    "        self.messages = system_msgs + other_msgs\n",
    "\n",
    "    def get_messages(self) -> List[Dict]:\n",
    "        \"\"\"Get all messages\"\"\"\n",
    "        return self.messages\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"Clear all except system messages\"\"\"\n",
    "        system_msgs = [m for m in self.messages if m[\"role\"] == \"system\"]\n",
    "        self.messages = system_msgs\n",
    "\n",
    "print(\"ShortTermMemory class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversational Agent with Short-Term Memory\n",
    "\n",
    "class ConversationalAgent:\n",
    "    \"\"\"Agent with conversation memory\"\"\"\n",
    "\n",
    "    def __init__(self, system_prompt: str = \"You are a helpful assistant.\"):\n",
    "        self.memory = ShortTermMemory(max_messages=20)\n",
    "        self.memory.add_system_message(system_prompt)\n",
    "\n",
    "    def chat(self, user_message: str) -> str:\n",
    "        \"\"\"Chat with memory\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"User: {user_message}\")\n",
    "\n",
    "        # Add to memory\n",
    "        self.memory.add_user_message(user_message)\n",
    "\n",
    "        # Get response\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=self.memory.get_messages()\n",
    "        )\n",
    "\n",
    "        assistant_message = response.choices[0].message.content\n",
    "        self.memory.add_assistant_message(assistant_message)\n",
    "\n",
    "        print(f\"Agent: {assistant_message}\")\n",
    "        print('='*60)\n",
    "\n",
    "        return assistant_message\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset conversation\"\"\"\n",
    "        self.memory.clear()\n",
    "        print(\"ðŸ”„ Conversation reset\")\n",
    "\n",
    "print(\"ConversationalAgent class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Short-Term Memory\n",
    "\n",
    "agent = ConversationalAgent()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONVERSATIONAL AGENT WITH SHORT-TERM MEMORY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Conversation demonstrating memory\n",
    "agent.chat(\"Hi, my name is Alice\")\n",
    "agent.chat(\"What's my name?\")  # Should remember: Alice\n",
    "agent.chat(\"I love Python programming\")\n",
    "agent.chat(\"What do I love?\")  # Should remember: Python\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Exercise 1A Complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Working Memory\n",
    "\n",
    "Working memory manages task context and progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Memory Implementation\n",
    "\n",
    "class WorkingMemory:\n",
    "    \"\"\"Manages task context and progress\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.task_name: Optional[str] = None\n",
    "        self.task_status: str = \"idle\"\n",
    "        self.variables: Dict[str, Any] = {}\n",
    "        self.steps_completed: list = []\n",
    "        self.current_step: Optional[str] = None\n",
    "        self.started_at: Optional[datetime] = None\n",
    "        self.completed_at: Optional[datetime] = None\n",
    "\n",
    "    def start_task(self, task_name: str):\n",
    "        \"\"\"Start a new task\"\"\"\n",
    "        self.task_name = task_name\n",
    "        self.task_status = \"in_progress\"\n",
    "        self.started_at = datetime.now()\n",
    "        self.variables = {}\n",
    "        self.steps_completed = []\n",
    "        print(f\"\\nðŸ“‹ Started task: {task_name}\")\n",
    "\n",
    "    def set_variable(self, key: str, value: Any):\n",
    "        \"\"\"Store a variable\"\"\"\n",
    "        self.variables[key] = value\n",
    "        print(f\"   ðŸ’¾ Stored: {key} = {value}\")\n",
    "\n",
    "    def get_variable(self, key: str) -> Any:\n",
    "        \"\"\"Retrieve a variable\"\"\"\n",
    "        return self.variables.get(key)\n",
    "\n",
    "    def complete_step(self, step_name: str):\n",
    "        \"\"\"Mark a step as completed\"\"\"\n",
    "        self.steps_completed.append({\n",
    "            \"step\": step_name,\n",
    "            \"completed_at\": datetime.now()\n",
    "        })\n",
    "        self.current_step = None\n",
    "        print(f\"   âœ… Completed step: {step_name}\")\n",
    "\n",
    "    def start_step(self, step_name: str):\n",
    "        \"\"\"Start a new step\"\"\"\n",
    "        self.current_step = step_name\n",
    "        print(f\"   ðŸ”„ Starting step: {step_name}\")\n",
    "\n",
    "    def complete_task(self, success: bool = True):\n",
    "        \"\"\"Complete the task\"\"\"\n",
    "        self.task_status = \"completed\" if success else \"failed\"\n",
    "        self.completed_at = datetime.now()\n",
    "\n",
    "        duration = (self.completed_at - self.started_at).total_seconds()\n",
    "        print(f\"\\n{'âœ…' if success else 'âŒ'} Task {self.task_status}: {self.task_name}\")\n",
    "        print(f\"   Duration: {duration:.2f}s\")\n",
    "        print(f\"   Steps completed: {len(self.steps_completed)}\")\n",
    "\n",
    "    def get_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get task summary\"\"\"\n",
    "        return {\n",
    "            \"task_name\": self.task_name,\n",
    "            \"status\": self.task_status,\n",
    "            \"steps_completed\": len(self.steps_completed),\n",
    "            \"variables\": self.variables\n",
    "        }\n",
    "\n",
    "print(\"WorkingMemory class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Working Memory\n",
    "\n",
    "memory = WorkingMemory()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WORKING MEMORY DEMONSTRATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Simulate a multi-step task\n",
    "memory.start_task(\"Calculate compound interest\")\n",
    "\n",
    "memory.start_step(\"Get input values\")\n",
    "memory.set_variable(\"principal\", 1000)\n",
    "memory.set_variable(\"rate\", 0.05)\n",
    "memory.set_variable(\"time\", 3)\n",
    "memory.complete_step(\"Get input values\")\n",
    "\n",
    "memory.start_step(\"Calculate final amount\")\n",
    "principal = memory.get_variable(\"principal\")\n",
    "rate = memory.get_variable(\"rate\")\n",
    "time = memory.get_variable(\"time\")\n",
    "amount = principal * ((1 + rate) ** time)\n",
    "memory.set_variable(\"final_amount\", amount)\n",
    "memory.complete_step(\"Calculate final amount\")\n",
    "\n",
    "memory.start_step(\"Calculate interest gained\")\n",
    "interest = amount - principal\n",
    "memory.set_variable(\"interest\", interest)\n",
    "memory.complete_step(\"Calculate interest gained\")\n",
    "\n",
    "memory.complete_task(success=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Task Summary:\")\n",
    "print(json.dumps(memory.get_summary(), indent=2))\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nâœ… Exercise 1B Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Long-Term Memory with ChromaDB\n",
    "\n",
    "Long-term memory uses a vector database for persistent storage with semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long-Term Memory Implementation\n",
    "\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class LongTermMemory:\n",
    "    \"\"\"Manages persistent memory with vector database\"\"\"\n",
    "\n",
    "    def __init__(self, collection_name: str = \"agent_memory\"):\n",
    "        # Initialize ChromaDB\n",
    "        self.client = chromadb.PersistentClient(path=\"./agent_memory_db\")\n",
    "\n",
    "        # Initialize embedding model\n",
    "        self.embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "        # Create or get collection\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name=collection_name,\n",
    "            metadata={\"description\": \"Agent long-term memory\"}\n",
    "        )\n",
    "\n",
    "        print(f\"âœ“ Long-term memory initialized\")\n",
    "        print(f\"  Collection: {collection_name}\")\n",
    "        print(f\"  Memories stored: {self.collection.count()}\")\n",
    "\n",
    "    def store_memory(\n",
    "        self,\n",
    "        content: str,\n",
    "        memory_type: str = \"general\",\n",
    "        metadata: Dict = None\n",
    "    ) -> str:\n",
    "        \"\"\"Store a memory\"\"\"\n",
    "        # Generate embedding\n",
    "        embedding = self.embedding_model.encode(content)\n",
    "\n",
    "        # Create unique ID\n",
    "        memory_id = f\"mem_{datetime.now().timestamp()}\"\n",
    "\n",
    "        # Prepare metadata\n",
    "        mem_metadata = {\n",
    "            \"type\": memory_type,\n",
    "            \"created_at\": datetime.now().isoformat(),\n",
    "            **(metadata or {})\n",
    "        }\n",
    "\n",
    "        # Store in ChromaDB\n",
    "        self.collection.add(\n",
    "            documents=[content],\n",
    "            embeddings=[embedding.tolist()],\n",
    "            ids=[memory_id],\n",
    "            metadatas=[mem_metadata]\n",
    "        )\n",
    "\n",
    "        print(f\"ðŸ’¾ Stored: {content[:50]}{'...' if len(content) > 50 else ''}\")\n",
    "        return memory_id\n",
    "\n",
    "    def retrieve_memories(\n",
    "        self,\n",
    "        query: str,\n",
    "        n_results: int = 5,\n",
    "        memory_type: str = None\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Retrieve relevant memories\"\"\"\n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embedding_model.encode(query)\n",
    "\n",
    "        # Build filter\n",
    "        where_filter = {\"type\": memory_type} if memory_type else None\n",
    "\n",
    "        # Search\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=[query_embedding.tolist()],\n",
    "            n_results=n_results,\n",
    "            where=where_filter,\n",
    "            include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "        )\n",
    "\n",
    "        # Format results\n",
    "        memories = []\n",
    "        if results['documents'] and results['documents'][0]:\n",
    "            for i in range(len(results['documents'][0])):\n",
    "                memories.append({\n",
    "                    \"content\": results['documents'][0][i],\n",
    "                    \"metadata\": results['metadatas'][0][i],\n",
    "                    \"relevance\": 1 / (1 + results['distances'][0][i])\n",
    "                })\n",
    "\n",
    "        return memories\n",
    "\n",
    "    def clear_memories(self):\n",
    "        \"\"\"Clear all memories\"\"\"\n",
    "        self.client.delete_collection(self.collection.name)\n",
    "        self.collection = self.client.create_collection(\n",
    "            name=self.collection.name,\n",
    "            metadata={\"description\": \"Agent long-term memory\"}\n",
    "        )\n",
    "        print(\"ðŸ—‘ï¸  Cleared all memories\")\n",
    "\n",
    "print(\"LongTermMemory class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Long-Term Memory\n",
    "\n",
    "ltm = LongTermMemory()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LONG-TERM MEMORY DEMONSTRATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Store some memories\n",
    "print(\"\\nðŸ“ Storing memories...\")\n",
    "ltm.store_memory(\n",
    "    \"User's name is Alice\",\n",
    "    memory_type=\"user_fact\"\n",
    ")\n",
    "\n",
    "ltm.store_memory(\n",
    "    \"User likes Python programming\",\n",
    "    memory_type=\"user_preference\"\n",
    ")\n",
    "\n",
    "ltm.store_memory(\n",
    "    \"User works as a data scientist\",\n",
    "    memory_type=\"user_fact\"\n",
    ")\n",
    "\n",
    "ltm.store_memory(\n",
    "    \"User prefers detailed explanations\",\n",
    "    memory_type=\"user_preference\"\n",
    ")\n",
    "\n",
    "# Retrieve relevant memories\n",
    "print(\"\\nðŸ” Querying memories...\")\n",
    "print(\"\\nQuery: 'What does the user do?'\")\n",
    "memories = ltm.retrieve_memories(\"What does the user do?\", n_results=3)\n",
    "\n",
    "for i, mem in enumerate(memories):\n",
    "    print(f\"\\n[{i+1}] Relevance: {mem['relevance']:.4f}\")\n",
    "    print(f\"    Content: {mem['content']}\")\n",
    "    print(f\"    Type: {mem['metadata']['type']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Exercise 1C Complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Checkpoint 1\n",
    "\n",
    "**What you learned:**\n",
    "- How to implement short-term memory for conversation history\n",
    "- How to use working memory for task tracking\n",
    "- How to build long-term memory with vector databases\n",
    "- Memory trimming and management strategies\n",
    "\n",
    "**Key Differences:**\n",
    "- **Short-term memory**: Recent conversation history (trimmed)\n",
    "- **Working memory**: Current task state and variables\n",
    "- **Long-term memory**: Persistent facts with semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: ReAct Agent\n",
    "\n",
    "Build an agent using the **Thought â†’ Action â†’ Observation** loop.\n",
    "\n",
    "ReAct (Reasoning + Acting) enables transparent, step-by-step problem solving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Tool Implementations for ReAct Agent\n\nimport ast\nimport operator\n\ndef safe_eval_math(expression: str) -> float:\n    \"\"\"Safely evaluate mathematical expressions without using eval()\"\"\"\n    # Define allowed operators\n    operators = {\n        ast.Add: operator.add,\n        ast.Sub: operator.sub,\n        ast.Mult: operator.mul,\n        ast.Div: operator.truediv,\n        ast.Pow: operator.pow,\n        ast.USub: operator.neg,\n    }\n    \n    def eval_node(node):\n        if isinstance(node, ast.Num):  # number\n            return node.n\n        elif isinstance(node, ast.BinOp):  # binary operation\n            return operators[type(node.op)](eval_node(node.left), eval_node(node.right))\n        elif isinstance(node, ast.UnaryOp):  # unary operation\n            return operators[type(node.op)](eval_node(node.operand))\n        else:\n            raise ValueError(f\"Unsupported operation: {type(node)}\")\n    \n    try:\n        tree = ast.parse(expression, mode='eval')\n        return eval_node(tree.body)\n    except Exception as e:\n        raise ValueError(f\"Invalid mathematical expression: {str(e)}\")\n\ndef calculator(expression: str) -> Dict[str, Any]:\n    \"\"\"Calculator tool with safe evaluation\"\"\"\n    try:\n        result = safe_eval_math(expression)\n        return {\"success\": True, \"result\": result}\n    except Exception as e:\n        return {\"success\": False, \"error\": str(e)}\n\ndef search_info(query: str) -> Dict[str, Any]:\n    \"\"\"Simulated search tool\"\"\"\n    knowledge = {\n        \"paris\": \"Paris is the capital of France with population of ~2.2 million (city proper). Founded in 3rd century BC.\",\n        \"python\": \"Python is a high-level programming language created by Guido van Rossum in 1991. Known for readability.\",\n        \"ai\": \"AI (Artificial Intelligence) is the simulation of human intelligence by machines and computer systems.\",\n        \"machine learning\": \"Machine learning is a subset of AI that enables systems to learn from data without explicit programming.\"\n    }\n\n    query_lower = query.lower()\n    for key, value in knowledge.items():\n        if key in query_lower:\n            return {\"success\": True, \"result\": value}\n\n    return {\"success\": False, \"result\": \"No information found\"}\n\nprint(\"Tools defined!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Definitions for OpenAI\n",
    "\n",
    "REACT_TOOLS = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculator\",\n",
    "            \"description\": \"Perform mathematical calculations\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Mathematical expression to evaluate\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"expression\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_info\",\n",
    "            \"description\": \"Search for information on a topic\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Search query\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "REACT_FUNCTIONS = {\n",
    "    \"calculator\": calculator,\n",
    "    \"search_info\": search_info\n",
    "}\n",
    "\n",
    "print(\"Tool definitions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct Agent Implementation\n",
    "\n",
    "def react_agent(user_query: str, verbose: bool = True):\n",
    "    \"\"\"\n",
    "    ReAct agent showing explicit reasoning\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"USER QUERY: {user_query}\")\n",
    "        print('='*70)\n",
    "\n",
    "    # System prompt for ReAct\n",
    "    system_prompt = \"\"\"You are a helpful assistant using the ReAct (Reasoning + Acting) framework.\n",
    "\n",
    "For each step:\n",
    "1. THINK about what to do next\n",
    "2. Use a tool if needed (ACTION)\n",
    "3. OBSERVE the result\n",
    "4. DECIDE if you have enough information\n",
    "\n",
    "Show your reasoning clearly by thinking step-by-step before each action.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_query}\n",
    "    ]\n",
    "\n",
    "    iteration = 0\n",
    "    max_iterations = 5\n",
    "\n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n{'â”€'*70}\")\n",
    "            print(f\"ITERATION {iteration}\")\n",
    "            print('â”€'*70)\n",
    "\n",
    "        # Get response\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            tools=REACT_TOOLS,\n",
    "            tool_choice=\"auto\"\n",
    "        )\n",
    "\n",
    "        response_message = response.choices[0].message\n",
    "\n",
    "        # Check if done\n",
    "        if not response_message.tool_calls:\n",
    "            final_answer = response_message.content\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"\\nðŸ’­ FINAL THOUGHT:\")\n",
    "                print(final_answer)\n",
    "                print('='*70)\n",
    "\n",
    "            return final_answer\n",
    "\n",
    "        # Show thinking\n",
    "        if verbose and response_message.content:\n",
    "            print(f\"\\nðŸ’­ THOUGHT:\")\n",
    "            print(response_message.content)\n",
    "\n",
    "        # Process tool calls (ACTIONS)\n",
    "        messages.append(response_message)\n",
    "\n",
    "        for tool_call in response_message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"\\nðŸ”§ ACTION: {function_name}\")\n",
    "                print(f\"   Args: {json.dumps(arguments)}\")\n",
    "\n",
    "            # Execute tool\n",
    "            function = REACT_FUNCTIONS[function_name]\n",
    "            result = function(**arguments)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"\\nðŸ‘ï¸  OBSERVATION:\")\n",
    "                print(f\"   {json.dumps(result, indent=3)}\")\n",
    "\n",
    "            # Add result to messages\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"name\": function_name,\n",
    "                \"content\": json.dumps(result)\n",
    "            })\n",
    "\n",
    "    return \"Max iterations reached\"\n",
    "\n",
    "print(\"ReAct agent defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ReAct Agent\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"REACT AGENT DEMONSTRATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test 1: Simple calculation\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"TEST 1: Simple Calculation\")\n",
    "print(\"#\"*70)\n",
    "react_agent(\"What is 25% of 840?\")\n",
    "\n",
    "# Test 2: Information retrieval\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"TEST 2: Information Retrieval\")\n",
    "print(\"#\"*70)\n",
    "react_agent(\"Tell me about Python programming language\")\n",
    "\n",
    "# Test 3: Multi-step reasoning\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"TEST 3: Multi-Step Reasoning\")\n",
    "print(\"#\"*70)\n",
    "react_agent(\"Search for Paris population, then calculate how many people per 100,000\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… Exercise 2 Complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Checkpoint 2\n",
    "\n",
    "**What you learned:**\n",
    "- The ReAct (Reasoning + Acting) framework\n",
    "- Thought â†’ Action â†’ Observation loop\n",
    "- Explicit reasoning for transparency\n",
    "- Multi-step problem solving\n",
    "\n",
    "**Key Insight**: ReAct makes agent reasoning visible, making it easier to debug and understand decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Planning Agent\n",
    "\n",
    "Build an agent that **creates a plan before executing**.\n",
    "\n",
    "This is the **plan-then-execute** pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planning Agent Implementation\n",
    "\n",
    "class PlanningAgent:\n",
    "    \"\"\"Agent that plans before executing\"\"\"\n",
    "\n",
    "    def __init__(self, tools, functions):\n",
    "        self.tools = tools\n",
    "        self.functions = functions\n",
    "        self.plan = []\n",
    "        self.execution_log = []\n",
    "\n",
    "    def create_plan(self, user_query: str) -> List[str]:\n",
    "        \"\"\"Create a step-by-step plan\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"PLANNING PHASE\")\n",
    "        print('='*70)\n",
    "\n",
    "        planning_prompt = f\"\"\"Given this task, create a detailed step-by-step plan.\n",
    "\n",
    "Task: {user_query}\n",
    "\n",
    "Available tools:\n",
    "- calculator: for mathematical calculations\n",
    "- search_info: for finding information\n",
    "\n",
    "Create a numbered plan with specific steps. Each step should be clear and actionable.\"\"\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a planning assistant. Create clear, actionable plans.\"},\n",
    "                {\"role\": \"user\", \"content\": planning_prompt}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        plan_text = response.choices[0].message.content\n",
    "        print(f\"\\nðŸ“‹ PLAN:\")\n",
    "        print(plan_text)\n",
    "\n",
    "        # Parse plan into steps\n",
    "        lines = plan_text.split('\\n')\n",
    "        steps = [line.strip() for line in lines if line.strip() and any(c.isdigit() for c in line[:3])]\n",
    "\n",
    "        self.plan = steps\n",
    "        return steps\n",
    "\n",
    "    def execute_plan(self) -> Dict:\n",
    "        \"\"\"Execute the created plan\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"EXECUTION PHASE\")\n",
    "        print('='*70)\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Execute the plan step by step. Follow each step carefully.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Execute this plan:\\n\" + \"\\n\".join(self.plan)}\n",
    "        ]\n",
    "\n",
    "        step_num = 0\n",
    "        max_iterations = len(self.plan) + 5\n",
    "\n",
    "        while step_num < max_iterations:\n",
    "            step_num += 1\n",
    "            print(f\"\\n{'â”€'*70}\")\n",
    "            print(f\"EXECUTION STEP {step_num}\")\n",
    "            print('â”€'*70)\n",
    "\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=messages,\n",
    "                tools=self.tools,\n",
    "                tool_choice=\"auto\"\n",
    "            )\n",
    "\n",
    "            response_message = response.choices[0].message\n",
    "\n",
    "            if response_message.content:\n",
    "                print(f\"ðŸ’­ {response_message.content[:150]}...\")\n",
    "\n",
    "            # Check if done\n",
    "            if not response_message.tool_calls:\n",
    "                final_answer = response_message.content\n",
    "                print(f\"\\nâœ… Execution complete!\")\n",
    "                print(f\"\\nFinal Answer:\\n{final_answer}\")\n",
    "                return {\n",
    "                    \"success\": True,\n",
    "                    \"answer\": final_answer,\n",
    "                    \"plan\": self.plan,\n",
    "                    \"execution_log\": self.execution_log\n",
    "                }\n",
    "\n",
    "            # Execute tools\n",
    "            messages.append(response_message)\n",
    "\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                print(f\"\\nðŸ”§ Tool: {function_name}\")\n",
    "                print(f\"   Args: {json.dumps(arguments)}\")\n",
    "\n",
    "                result = self.functions[function_name](**arguments)\n",
    "\n",
    "                print(f\"   Result: {json.dumps(result)}\")\n",
    "\n",
    "                self.execution_log.append({\n",
    "                    \"step\": step_num,\n",
    "                    \"tool\": function_name,\n",
    "                    \"arguments\": arguments,\n",
    "                    \"result\": result\n",
    "                })\n",
    "\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": json.dumps(result)\n",
    "                })\n",
    "\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": \"Max iterations reached\"\n",
    "        }\n",
    "\n",
    "    def plan_and_execute(self, user_query: str) -> Dict:\n",
    "        \"\"\"Complete plan-then-execute workflow\"\"\"\n",
    "        # Phase 1: Planning\n",
    "        self.create_plan(user_query)\n",
    "\n",
    "        # Phase 2: Execution\n",
    "        result = self.execute_plan()\n",
    "\n",
    "        return result\n",
    "\n",
    "print(\"PlanningAgent class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Planning Agent\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PLANNING AGENT DEMONSTRATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "agent = PlanningAgent(REACT_TOOLS, REACT_FUNCTIONS)\n",
    "\n",
    "result = agent.plan_and_execute(\n",
    "    \"Find information about machine learning, then calculate how many years it's been since AI was coined in 1956 (current year 2024)\"\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SUMMARY\")\n",
    "print('='*70)\n",
    "print(f\"Success: {result['success']}\")\n",
    "print(f\"Steps in plan: {len(result.get('plan', []))}\")\n",
    "print(f\"Tools executed: {len(result.get('execution_log', []))}\")\n",
    "\n",
    "print(\"\\nâœ… Exercise 3 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Checkpoint 3\n",
    "\n",
    "**What you learned:**\n",
    "- Plan-then-execute pattern\n",
    "- Creating structured plans from goals\n",
    "- Executing plans systematically\n",
    "- Tracking execution progress\n",
    "\n",
    "**When to use planning**: Complex multi-step tasks benefit from upfront planning to avoid getting stuck or taking inefficient paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Self-Reflective Agent\n",
    "\n",
    "Build an agent that **reflects on its progress** and adjusts course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reflective Agent Implementation\n",
    "\n",
    "class ReflectiveAgent:\n",
    "    \"\"\"Agent with self-reflection capabilities\"\"\"\n",
    "\n",
    "    def __init__(self, tools, functions):\n",
    "        self.tools = tools\n",
    "        self.functions = functions\n",
    "        self.reflection_history = []\n",
    "        self.action_history = []\n",
    "\n",
    "    def reflect(self, action_history: List[Dict]) -> str:\n",
    "        \"\"\"Reflect on actions taken\"\"\"\n",
    "        if not action_history:\n",
    "            return \"\"\n",
    "\n",
    "        history_text = \"Actions taken so far:\\n\"\n",
    "        for i, action in enumerate(action_history):\n",
    "            history_text += f\"{i+1}. {action['tool']}({json.dumps(action['args'])}) â†’ {action['result']}\\n\"\n",
    "\n",
    "        reflection_prompt = f\"\"\"{history_text}\n",
    "\n",
    "Reflect on these actions:\n",
    "1. Are we making progress toward the goal?\n",
    "2. Did any action fail or produce unexpected results?\n",
    "3. Should we change our approach?\n",
    "4. What should we do next?\n",
    "\n",
    "Provide a brief reflection.\"\"\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a reflective assistant that evaluates progress.\"},\n",
    "                {\"role\": \"user\", \"content\": reflection_prompt}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        reflection = response.choices[0].message.content\n",
    "        return reflection\n",
    "\n",
    "    def run(self, user_query: str, reflection_interval: int = 3):\n",
    "        \"\"\"Run agent with periodic reflection\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"TASK: {user_query}\")\n",
    "        print('='*70)\n",
    "\n",
    "        system_prompt = \"\"\"You are a thoughtful ReAct agent that learns from mistakes.\n",
    "\n",
    "Use the ReAct framework:\n",
    "- THOUGHT: Reason about what to do\n",
    "- ACTION: Use a tool\n",
    "- OBSERVATION: Analyze the result\n",
    "- REFLECTION: Evaluate if approach is working\n",
    "\n",
    "If something fails, try a different approach.\"\"\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_query}\n",
    "        ]\n",
    "\n",
    "        iteration = 0\n",
    "        max_iterations = 10\n",
    "\n",
    "        while iteration < max_iterations:\n",
    "            iteration += 1\n",
    "            print(f\"\\n{'â”€'*70}\")\n",
    "            print(f\"ITERATION {iteration}\")\n",
    "            print('â”€'*70)\n",
    "\n",
    "            # Periodic reflection\n",
    "            if len(self.action_history) > 0 and len(self.action_history) % reflection_interval == 0:\n",
    "                reflection = self.reflect(self.action_history)\n",
    "                print(f\"\\nðŸ¤” REFLECTION:\")\n",
    "                print(reflection)\n",
    "\n",
    "                self.reflection_history.append({\n",
    "                    \"iteration\": iteration,\n",
    "                    \"reflection\": reflection\n",
    "                })\n",
    "\n",
    "                # Add reflection to context\n",
    "                messages.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Reflection on progress: {reflection}\"\n",
    "                })\n",
    "\n",
    "            # Get next action\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=messages,\n",
    "                tools=self.tools,\n",
    "                tool_choice=\"auto\"\n",
    "            )\n",
    "\n",
    "            response_message = response.choices[0].message\n",
    "\n",
    "            if response_message.content:\n",
    "                print(f\"\\nðŸ’­ {response_message.content}\")\n",
    "\n",
    "            # Check if done\n",
    "            if not response_message.tool_calls:\n",
    "                print(f\"\\nâœ… COMPLETE\")\n",
    "                return {\n",
    "                    \"answer\": response_message.content,\n",
    "                    \"action_history\": self.action_history,\n",
    "                    \"reflections\": self.reflection_history,\n",
    "                    \"iterations\": iteration\n",
    "                }\n",
    "\n",
    "            # Execute actions\n",
    "            messages.append(response_message)\n",
    "\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                print(f\"\\nðŸ”§ ACTION: {function_name}({json.dumps(arguments)})\")\n",
    "\n",
    "                # Execute\n",
    "                try:\n",
    "                    result = self.functions[function_name](**arguments)\n",
    "                    success = result.get(\"success\", True) if isinstance(result, dict) else True\n",
    "                except Exception as e:\n",
    "                    result = {\"success\": False, \"error\": str(e)}\n",
    "                    success = False\n",
    "\n",
    "                print(f\"ðŸ‘ï¸  OBSERVATION: {json.dumps(result)}\")\n",
    "\n",
    "                if not success:\n",
    "                    print(\"âš ï¸  Action failed!\")\n",
    "\n",
    "                # Record action\n",
    "                self.action_history.append({\n",
    "                    \"tool\": function_name,\n",
    "                    \"args\": arguments,\n",
    "                    \"result\": result,\n",
    "                    \"success\": success\n",
    "                })\n",
    "\n",
    "                # Add to messages\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": json.dumps(result)\n",
    "                })\n",
    "\n",
    "        return {\n",
    "            \"answer\": \"Max iterations reached\",\n",
    "            \"action_history\": self.action_history,\n",
    "            \"reflections\": self.reflection_history\n",
    "        }\n",
    "\n",
    "print(\"ReflectiveAgent class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Reflective Agent\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"REFLECTIVE AGENT DEMONSTRATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "agent = ReflectiveAgent(REACT_TOOLS, REACT_FUNCTIONS)\n",
    "\n",
    "result = agent.run(\n",
    "    \"Calculate 20% of 500, search for info about AI, then calculate 10% of the first result\",\n",
    "    reflection_interval=2\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SUMMARY\")\n",
    "print('='*70)\n",
    "print(f\"Iterations: {result['iterations']}\")\n",
    "print(f\"Actions taken: {len(result['action_history'])}\")\n",
    "print(f\"Reflections made: {len(result['reflections'])}\")\n",
    "\n",
    "print(\"\\nâœ… Exercise 4 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Checkpoint 4\n",
    "\n",
    "**What you learned:**\n",
    "- Self-reflection for progress evaluation\n",
    "- Error detection and course correction\n",
    "- Adaptive agent behavior\n",
    "- Learning from mistakes\n",
    "\n",
    "**Key Benefit**: Reflection allows agents to detect when they're stuck or going down the wrong path, enabling adaptive behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Project: IntelliAgent v1.0\n",
    "\n",
    "Build a **complete intelligent agent** combining all concepts:\n",
    "- Full memory system (short-term + working + long-term)\n",
    "- ReAct framework with explicit reasoning\n",
    "- Self-reflection and error correction\n",
    "- Production-ready error handling\n",
    "\n",
    "This is your **production-ready intelligent agent**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IntelliAgent v1.0 - Complete Intelligent Agent\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class IntelliAgent:\n",
    "    \"\"\"\n",
    "    Production-ready intelligent agent with:\n",
    "    - Full memory system (short-term, working, long-term)\n",
    "    - ReAct framework\n",
    "    - Planning capabilities\n",
    "    - Self-reflection\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str = \"IntelliAgent\"):\n",
    "        self.name = name\n",
    "\n",
    "        # Memory systems\n",
    "        self.short_term = ShortTermMemory(max_messages=20)\n",
    "        self.working = WorkingMemory()\n",
    "        self.long_term = LongTermMemory(collection_name=f\"{name.lower()}_memory\")\n",
    "\n",
    "        # Tools\n",
    "        self.tools = self._setup_tools()\n",
    "        self.functions = {\n",
    "            \"calculator\": calculator,\n",
    "            \"search_info\": search_info\n",
    "        }\n",
    "\n",
    "        # State\n",
    "        self.action_history = []\n",
    "        self.reflection_history = []\n",
    "\n",
    "        # System prompt\n",
    "        system_prompt = f\"\"\"You are {name}, an intelligent assistant with memory and planning capabilities.\n",
    "\n",
    "You use the ReAct framework:\n",
    "1. THOUGHT: Reason about what to do next\n",
    "2. ACTION: Use tools when needed\n",
    "3. OBSERVATION: Analyze results\n",
    "4. REFLECTION: Periodically evaluate progress\n",
    "\n",
    "You have access to:\n",
    "- Short-term memory (conversation history)\n",
    "- Working memory (task variables)\n",
    "- Long-term memory (persistent facts)\n",
    "\n",
    "Plan complex tasks before executing. Reflect on your progress. Learn from mistakes.\"\"\"\n",
    "\n",
    "        self.short_term.add_system_message(system_prompt)\n",
    "\n",
    "        logger.info(f\"{name} initialized with full capabilities\")\n",
    "\n",
    "    def _setup_tools(self):\n",
    "        \"\"\"Setup tool definitions\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"calculator\",\n",
    "                    \"description\": \"Perform mathematical calculations\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"expression\": {\"type\": \"string\", \"description\": \"Math expression\"}\n",
    "                        },\n",
    "                        \"required\": [\"expression\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"search_info\",\n",
    "                    \"description\": \"Search for information\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"query\": {\"type\": \"string\", \"description\": \"Search query\"}\n",
    "                        },\n",
    "                        \"required\": [\"query\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def remember(self, fact: str, memory_type: str = \"user_fact\"):\n",
    "        \"\"\"Store in long-term memory\"\"\"\n",
    "        self.long_term.store_memory(fact, memory_type=memory_type)\n",
    "        logger.info(f\"Stored memory: {fact}\")\n",
    "\n",
    "    def reflect(self) -> str:\n",
    "        \"\"\"Reflect on recent actions\"\"\"\n",
    "        if not self.action_history:\n",
    "            return \"\"\n",
    "\n",
    "        recent_actions = self.action_history[-5:]  # Last 5 actions\n",
    "        history_text = \"Recent actions:\\n\"\n",
    "        for i, action in enumerate(recent_actions):\n",
    "            history_text += f\"{i+1}. {action['tool']} â†’ {action.get('success', 'unknown')}\\n\"\n",
    "\n",
    "        reflection_prompt = f\"\"\"{history_text}\n",
    "\n",
    "Quick reflection: Are we making progress? Any issues?\"\"\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": reflection_prompt}]\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def execute_task(self, user_message: str, use_long_term: bool = True, max_iterations: int = 10):\n",
    "        \"\"\"\n",
    "        Execute a task with full capabilities\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"{self.name}: EXECUTING TASK\")\n",
    "        print('='*70)\n",
    "        print(f\"Task: {user_message}\\n\")\n",
    "\n",
    "        # Start task in working memory\n",
    "        self.working.start_task(user_message)\n",
    "\n",
    "        # Retrieve relevant long-term memories\n",
    "        if use_long_term and self.long_term.collection.count() > 0:\n",
    "            memories = self.long_term.retrieve_memories(user_message, n_results=3)\n",
    "            if memories and memories[0]['relevance'] > 0.5:\n",
    "                print(\"ðŸ§  Retrieved memories:\")\n",
    "                memory_context = \"Relevant memories:\\n\"\n",
    "                for mem in memories[:3]:\n",
    "                    if mem['relevance'] > 0.5:\n",
    "                        print(f\"   â€¢ {mem['content']}\")\n",
    "                        memory_context += f\"- {mem['content']}\\n\"\n",
    "\n",
    "                # Add to short-term memory\n",
    "                self.short_term.add_user_message(f\"{memory_context}\\nTask: {user_message}\")\n",
    "            else:\n",
    "                self.short_term.add_user_message(user_message)\n",
    "        else:\n",
    "            self.short_term.add_user_message(user_message)\n",
    "\n",
    "        # Main execution loop\n",
    "        iteration = 0\n",
    "\n",
    "        while iteration < max_iterations:\n",
    "            iteration += 1\n",
    "            print(f\"\\n{'â”€'*60}\")\n",
    "            print(f\"Iteration {iteration}\")\n",
    "            print('â”€'*60)\n",
    "\n",
    "            # Reflection every 3 iterations\n",
    "            if iteration > 1 and iteration % 3 == 0:\n",
    "                reflection = self.reflect()\n",
    "                print(f\"\\nðŸ¤” Reflection: {reflection[:100]}...\")\n",
    "                self.reflection_history.append(reflection)\n",
    "\n",
    "            # Get response\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=self.short_term.get_messages(),\n",
    "                    tools=self.tools,\n",
    "                    tool_choice=\"auto\"\n",
    "                )\n",
    "\n",
    "                response_message = response.choices[0].message\n",
    "\n",
    "                # Check if done\n",
    "                if not response_message.tool_calls:\n",
    "                    final_answer = response_message.content\n",
    "                    self.short_term.add_assistant_message(final_answer)\n",
    "                    self.working.complete_task(success=True)\n",
    "\n",
    "                    print(f\"\\nâœ… COMPLETE\")\n",
    "                    print(f\"\\n{self.name}: {final_answer}\")\n",
    "                    print('='*70)\n",
    "\n",
    "                    return {\n",
    "                        \"success\": True,\n",
    "                        \"answer\": final_answer,\n",
    "                        \"iterations\": iteration,\n",
    "                        \"actions\": len(self.action_history),\n",
    "                        \"reflections\": len(self.reflection_history)\n",
    "                    }\n",
    "\n",
    "                # Show reasoning\n",
    "                if response_message.content:\n",
    "                    print(f\"ðŸ’­ {response_message.content[:100]}...\")\n",
    "\n",
    "                # Execute tools\n",
    "                self.short_term.messages.append(response_message)\n",
    "\n",
    "                for tool_call in response_message.tool_calls:\n",
    "                    function_name = tool_call.function.name\n",
    "                    arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                    print(f\"\\nðŸ”§ {function_name}({json.dumps(arguments)})\")\n",
    "\n",
    "                    # Execute\n",
    "                    result = self.functions[function_name](**arguments)\n",
    "                    success = result.get(\"success\", True) if isinstance(result, dict) else True\n",
    "\n",
    "                    print(f\"   Result: {json.dumps(result)}\")\n",
    "\n",
    "                    # Record action\n",
    "                    self.action_history.append({\n",
    "                        \"iteration\": iteration,\n",
    "                        \"tool\": function_name,\n",
    "                        \"args\": arguments,\n",
    "                        \"result\": result,\n",
    "                        \"success\": success\n",
    "                    })\n",
    "\n",
    "                    # Store in working memory if result has data\n",
    "                    if success and isinstance(result, dict) and \"result\" in result:\n",
    "                        self.working.set_variable(f\"{function_name}_result\", result[\"result\"])\n",
    "\n",
    "                    # Add to conversation\n",
    "                    self.short_term.messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": json.dumps(result)\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in iteration {iteration}: {str(e)}\")\n",
    "                self.working.complete_task(success=False)\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"error\": str(e),\n",
    "                    \"iterations\": iteration\n",
    "                }\n",
    "\n",
    "        # Max iterations reached\n",
    "        self.working.complete_task(success=False)\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": \"Max iterations reached\",\n",
    "            \"iterations\": iteration\n",
    "        }\n",
    "\n",
    "print(\"IntelliAgent v1.0 class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate IntelliAgent Capabilities\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ§  INTELLIAGENT v1.0 - INTELLIGENT AGENT SYSTEM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "agent = IntelliAgent(name=\"IntelliAgent\")\n",
    "\n",
    "# Store some long-term memories\n",
    "print(\"\\nðŸ“ Storing long-term memories...\")\n",
    "agent.remember(\"User's name is Bob\", memory_type=\"user_fact\")\n",
    "agent.remember(\"User loves data science\", memory_type=\"user_preference\")\n",
    "\n",
    "# Test tasks\n",
    "test_tasks = [\n",
    "    \"Calculate 15% of 600\",\n",
    "    \"What is Python and when was it created?\",\n",
    "    \"Calculate 20% of 500, then search for info about machine learning\",\n",
    "]\n",
    "\n",
    "for i, task in enumerate(test_tasks, 1):\n",
    "    print(f\"\\n{'#'*70}\")\n",
    "    print(f\"TASK {i}/{len(test_tasks)}\")\n",
    "    print('#'*70)\n",
    "\n",
    "    result = agent.execute_task(task)\n",
    "\n",
    "    print(f\"\\nðŸ“Š Task Summary:\")\n",
    "    print(f\"   Success: {result['success']}\")\n",
    "    print(f\"   Iterations: {result.get('iterations', 0)}\")\n",
    "    print(f\"   Actions: {result.get('actions', 0)}\")\n",
    "    print(f\"   Reflections: {result.get('reflections', 0)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… DEMONSTRATION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nIntelliAgent v1.0 Statistics:\")\n",
    "print(f\"  â€¢ Total actions: {len(agent.action_history)}\")\n",
    "print(f\"  â€¢ Reflections: {len(agent.reflection_history)}\")\n",
    "print(f\"  â€¢ Long-term memories: {agent.long_term.collection.count()}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Lab Complete!\n",
    "\n",
    "Congratulations! You've built a complete intelligent agent system.\n",
    "\n",
    "### What You Accomplished:\n",
    "\n",
    "1. **Memory systems** - Short-term, working, and long-term memory\n",
    "2. **ReAct agents** - Transparent reasoning with Thought â†’ Action â†’ Observation\n",
    "3. **Planning agents** - Create strategies before executing\n",
    "4. **Reflective agents** - Self-evaluate and adjust course\n",
    "5. **IntelliAgent v1.0** - Complete intelligent agent system\n",
    "\n",
    "### Key Concepts Mastered:\n",
    "\n",
    "**Memory:**\n",
    "- Short-term memory for conversation history\n",
    "- Working memory for task state\n",
    "- Long-term memory with vector databases\n",
    "- Memory retrieval with semantic search\n",
    "\n",
    "**Planning & Reasoning:**\n",
    "- ReAct framework (Reasoning + Acting)\n",
    "- Plan-then-execute pattern\n",
    "- Self-reflection and error correction\n",
    "- Dynamic replanning\n",
    "\n",
    "**Production Skills:**\n",
    "- Error handling in agents\n",
    "- Logging and monitoring\n",
    "- Modular agent architecture\n",
    "- Memory management strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Challenges\n",
    "\n",
    "Ready to extend IntelliAgent? Try these:\n",
    "\n",
    "### Challenge 1: Hierarchical Planning\n",
    "Build an agent that:\n",
    "1. Breaks complex tasks into subtasks\n",
    "2. Creates plans for each subtask\n",
    "3. Executes in dependency order\n",
    "4. Tracks progress hierarchically\n",
    "\n",
    "### Challenge 2: Memory Decay\n",
    "Implement memory decay where:\n",
    "1. Old memories become less relevant over time\n",
    "2. Relevance score decreases with age\n",
    "3. Very old memories are archived or deleted\n",
    "4. Important memories are preserved\n",
    "\n",
    "### Challenge 3: Multi-Agent Collaboration\n",
    "Create multiple specialized agents that:\n",
    "1. Each have their own memory and expertise\n",
    "2. Communicate and share information\n",
    "3. Delegate tasks to appropriate agent\n",
    "4. Combine results from multiple agents\n",
    "\n",
    "### Challenge 4: Dynamic Replanning\n",
    "Add replanning when:\n",
    "1. Actions fail repeatedly\n",
    "2. Goals change mid-execution\n",
    "3. New information becomes available\n",
    "4. Resource constraints are hit\n",
    "\n",
    "### Challenge 5: Memory Consolidation\n",
    "Implement:\n",
    "1. Merge similar memories to reduce duplication\n",
    "2. Summarize old conversations before archiving\n",
    "3. Extract key facts from conversation history\n",
    "4. Store failed approaches to avoid repeating mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Memory Architecture:\n",
    "- Use **short-term memory** for conversation context (trimmed)\n",
    "- Use **working memory** for current task state\n",
    "- Use **long-term memory** for persistent facts (vector DB)\n",
    "- Combine all three for complete agent memory\n",
    "\n",
    "### Agent Patterns:\n",
    "- **ReAct**: Explicit reasoning makes agents debuggable\n",
    "- **Planning**: Upfront planning prevents inefficient paths\n",
    "- **Reflection**: Periodic self-evaluation enables adaptation\n",
    "- **Combination**: Real agents use all patterns together\n",
    "\n",
    "### Production Considerations:\n",
    "- Always implement error handling and logging\n",
    "- Set reasonable iteration limits to prevent loops\n",
    "- Monitor agent behavior and costs\n",
    "- Use reflection to detect and recover from failures\n",
    "- Test edge cases and failure scenarios\n",
    "\n",
    "### Next Steps:\n",
    "- Explore async agent execution for parallelism\n",
    "- Implement streaming responses for better UX\n",
    "- Add conversation memory and context windows\n",
    "- Build agent analytics and monitoring dashboards\n",
    "- Deploy to production with proper scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Prompt Engineering\n",
    "\n",
    "## üõ†Ô∏è Hands-On Lab\n",
    "\n",
    "**Duration**: 60-90 minutes  \n",
    "**Difficulty**: Beginner to Intermediate  \n",
    "**Prerequisites**: Lab 1 completed\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Build\n",
    "\n",
    "By the end of this lab, you'll have:\n",
    "- ‚úÖ Mastered prompt construction techniques\n",
    "- ‚úÖ Created reusable prompt templates\n",
    "- ‚úÖ Implemented few-shot learning patterns\n",
    "- ‚úÖ Built edge case handlers\n",
    "- ‚úÖ **Capstone**: Enhanced SupportGenie v0.2 with advanced prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Setup\n",
    "\n",
    "### Step 1: Verify Environment\n",
    "\n",
    "Make sure you completed Lab 1 setup. Your `.env` file should have API keys.\n",
    "\n",
    "### Step 2: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Understanding Prompt Quality (15 min)\n",
    "\n",
    "**Objective**: Experience the difference between vague and specific prompts.\n",
    "\n",
    "### Task 1A: Test Vague Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vague_prompt():\n",
    "    \"\"\"Test how LLMs respond to vague prompts\"\"\"\n",
    "\n",
    "    vague_prompt = \"Tell me about returns\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": vague_prompt}\n",
    "        ],\n",
    "        max_tokens=150\n",
    "    )\n",
    "\n",
    "    print(\"=== VAGUE PROMPT ===\")\n",
    "    print(f\"Prompt: {vague_prompt}\")\n",
    "    print(f\"\\nResponse:\\n{response.choices[0].message.content}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "test_vague_prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Behavior**: The response will be unfocused - it might discuss financial returns, product returns, programming return statements, etc.\n",
    "\n",
    "### Task 1B: Test Specific Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_specific_prompt():\n",
    "    \"\"\"Test how LLMs respond to specific, well-structured prompts\"\"\"\n",
    "\n",
    "    specific_prompt = \"\"\"\n",
    "As a customer service agent for TechStore (an electronics retailer),\n",
    "explain our 30-day product return policy.\n",
    "\n",
    "Include:\n",
    "- Eligibility requirements\n",
    "- Return process steps\n",
    "- Timeframe for refunds\n",
    "\n",
    "Keep it under 100 words and use a professional, helpful tone.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": specific_prompt}\n",
    "        ],\n",
    "        max_tokens=200\n",
    "    )\n",
    "\n",
    "    print(\"=== SPECIFIC PROMPT ===\")\n",
    "    print(f\"Prompt: {specific_prompt}\")\n",
    "    print(f\"\\nResponse:\\n{response.choices[0].message.content}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "test_specific_prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Behavior**: Focused, relevant response specifically about product return policies.\n",
    "\n",
    "### Task 1C: Compare Results\n",
    "\n",
    "Run both functions and observe:\n",
    "- Which response is more useful?\n",
    "- Which response stays on topic?\n",
    "- Which response has appropriate length?\n",
    "\n",
    "‚úÖ **Checkpoint**: You should see dramatically different response quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: System Messages (15 min)\n",
    "\n",
    "**Objective**: Learn how system messages control AI behavior across conversations.\n",
    "\n",
    "### Task 2A: Build System Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_system_message(system_msg, user_msg):\n",
    "    \"\"\"Helper function to test different system messages\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg}\n",
    "        ],\n",
    "        max_tokens=150\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test Case 1: Vague system message\n",
    "vague_system = \"You are a helpful assistant.\"\n",
    "\n",
    "# Test Case 2: Specific system message\n",
    "specific_system = \"\"\"\n",
    "You are SupportGenie, a customer service AI for TechStore.\n",
    "\n",
    "Guidelines:\n",
    "- Be professional and empathetic\n",
    "- Keep responses under 75 words\n",
    "- Always offer to escalate if needed\n",
    "- Never make up information about products or policies\n",
    "\n",
    "Response Format:\n",
    "1. Acknowledge the customer's concern\n",
    "2. Provide solution or information\n",
    "3. Ask if they need additional help\n",
    "\"\"\"\n",
    "\n",
    "# Test with same user message\n",
    "user_message = \"My order hasn't arrived yet!\"\n",
    "\n",
    "print(\"=== VAGUE SYSTEM MESSAGE ===\")\n",
    "response1 = chat_with_system_message(vague_system, user_message)\n",
    "print(f\"Response: {response1}\\n\")\n",
    "\n",
    "print(\"=== SPECIFIC SYSTEM MESSAGE ===\")\n",
    "response2 = chat_with_system_message(specific_system, user_message)\n",
    "print(f\"Response: {response2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2B: Create Your Own System Message\n",
    "\n",
    "**Your Turn**: Create a system message for a different role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Tech support bot\n",
    "your_system_message = \"\"\"\n",
    "# TODO: Create a system message for a technical support bot\n",
    "# that helps customers troubleshoot laptop issues.\n",
    "#\n",
    "# Include:\n",
    "# - Role and expertise\n",
    "# - Constraints (ask one question at a time)\n",
    "# - Tone (patient and clear)\n",
    "# - Response format\n",
    "\"\"\"\n",
    "\n",
    "# Test it\n",
    "user_message = \"My laptop is running really slow\"\n",
    "response = chat_with_system_message(your_system_message, user_message)\n",
    "print(f\"Your Bot's Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ **Checkpoint**: Your system message should produce focused, helpful technical troubleshooting responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Few-Shot Learning (20 min)\n",
    "\n",
    "**Objective**: Use examples to guide consistent output formatting.\n",
    "\n",
    "### Task 3A: Zero-Shot (No Examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_zero_shot(text):\n",
    "    \"\"\"Extract customer info without examples\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Extract the customer name and email from this message.\n",
    "Return as JSON.\n",
    "\n",
    "Message: {text}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=100\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test\n",
    "test_message = \"Hi, I'm John Smith. Contact me at john@email.com\"\n",
    "result = extract_info_zero_shot(test_message)\n",
    "print(\"Zero-Shot Result:\")\n",
    "print(result)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Format may be inconsistent across different inputs.\n",
    "\n",
    "### Task 3B: Few-Shot (With Examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_few_shot(text):\n",
    "    \"\"\"Extract customer info with examples for consistency\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Extract customer name and email from text. Return as JSON.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Text: \"My name is Alice Johnson, email alice@test.com\"\n",
    "Output: {{\"name\": \"Alice Johnson\", \"email\": \"alice@test.com\"}}\n",
    "\n",
    "Text: \"I'm Bob Lee (bob.lee@company.com)\"\n",
    "Output: {{\"name\": \"Bob Lee\", \"email\": \"bob.lee@company.com\"}}\n",
    "\n",
    "Text: \"Contact Sarah Martinez at s.martinez@mail.com for details\"\n",
    "Output: {{\"name\": \"Sarah Martinez\", \"email\": \"s.martinez@mail.com\"}}\n",
    "\n",
    "Now extract from:\n",
    "Text: \"{text}\"\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=100,\n",
    "        temperature=0.3  # Lower temperature for more consistent formatting\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test with multiple inputs\n",
    "test_messages = [\n",
    "    \"Hi, I'm John Smith. Contact me at john@email.com\",\n",
    "    \"This is Jennifer Wu, reach me at jwu@company.org\",\n",
    "    \"My email is mike.brown@test.net - Mike Brown\"\n",
    "]\n",
    "\n",
    "print(\"Few-Shot Results:\")\n",
    "for msg in test_messages:\n",
    "    result = extract_info_few_shot(msg)\n",
    "    print(f\"Input: {msg}\")\n",
    "    print(f\"Output: {result}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ **Checkpoint**: Few-shot results should have consistent JSON format.\n",
    "\n",
    "### Task 3C: Your Turn - Sentiment Classification\n",
    "\n",
    "**Challenge**: Create a few-shot prompt for classifying customer message sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(message):\n",
    "    \"\"\"\n",
    "    TODO: Create a few-shot prompt to classify sentiment as:\n",
    "    - positive\n",
    "    - negative\n",
    "    - neutral\n",
    "\n",
    "    Provide 3-4 examples in your prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "# Your few-shot prompt here\n",
    "# Include examples of positive, negative, and neutral messages\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=50,\n",
    "        temperature=0.3\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test cases\n",
    "test_sentiments = [\n",
    "    \"I love this product! Works perfectly.\",\n",
    "    \"Terrible experience. Product broke after 2 days.\",\n",
    "    \"The item arrived. It's okay, I guess.\",\n",
    "    \"WHERE IS MY ORDER?! I've been waiting 3 weeks!\"\n",
    "]\n",
    "\n",
    "for msg in test_sentiments:\n",
    "    sentiment = classify_sentiment(msg)\n",
    "    print(f\"Message: {msg}\")\n",
    "    print(f\"Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ **Checkpoint**: Should correctly classify all test cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Chain-of-Thought Prompting (15 min)\n",
    "\n",
    "**Objective**: Use step-by-step reasoning for complex problems.\n",
    "\n",
    "### Task 4A: Problem Without CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_no_cot(items, discount_percent, shipping):\n",
    "    \"\"\"Calculate order total WITHOUT chain-of-thought\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Calculate the total cost:\n",
    "- {items} items at $50 each\n",
    "- {discount_percent}% discount\n",
    "- ${shipping} shipping\n",
    "\n",
    "Total:\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=50\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "result = calculate_total_no_cot(3, 20, 5)\n",
    "print(\"Without CoT:\")\n",
    "print(result)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4B: Problem With CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_with_cot(items, discount_percent, shipping):\n",
    "    \"\"\"Calculate order total WITH chain-of-thought reasoning\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Calculate the total cost step by step:\n",
    "\n",
    "Problem:\n",
    "- {items} items at $50 each\n",
    "- {discount_percent}% discount code\n",
    "- ${shipping} shipping\n",
    "\n",
    "Please solve this step by step:\n",
    "\n",
    "Step 1: Calculate subtotal (items √ó price)\n",
    "Step 2: Apply discount\n",
    "Step 3: Add shipping\n",
    "Step 4: Provide final total\n",
    "\n",
    "Solution:\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=200\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "result = calculate_total_with_cot(3, 20, 5)\n",
    "print(\"With CoT:\")\n",
    "print(result)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observe**: The CoT version shows its work, making it easier to verify correctness.\n",
    "\n",
    "### Task 4C: Your Turn - Troubleshooting with CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def troubleshoot_with_cot(issue):\n",
    "    \"\"\"\n",
    "    TODO: Create a CoT prompt for troubleshooting technical issues.\n",
    "\n",
    "    The prompt should ask the LLM to:\n",
    "    1. Identify the problem type\n",
    "    2. List possible causes\n",
    "    3. Suggest diagnostic questions\n",
    "    4. Recommend solutions\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "# Your CoT troubleshooting prompt here\n",
    "Issue: {issue}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=300\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test\n",
    "issue = \"Customer's laptop won't turn on\"\n",
    "solution = troubleshoot_with_cot(issue)\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ **Checkpoint**: Should see step-by-step reasoning for troubleshooting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Prompt Templates (20 min)\n",
    "\n",
    "**Objective**: Build reusable, maintainable prompt templates.\n",
    "\n",
    "### Task 5A: Create Template Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptTemplate:\n",
    "    \"\"\"Reusable prompt template with variable substitution\"\"\"\n",
    "\n",
    "    def __init__(self, template, variables):\n",
    "        self.template = template\n",
    "        self.variables = variables\n",
    "\n",
    "    def format(self, **kwargs):\n",
    "        \"\"\"Format template with provided values\"\"\"\n",
    "\n",
    "        # Validate all required variables are provided\n",
    "        missing = set(self.variables) - set(kwargs.keys())\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required variables: {missing}\")\n",
    "\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "# Test the class\n",
    "product_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "As a product expert for {company}, answer this question about {product}.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Guidelines:\n",
    "- Be accurate and detailed\n",
    "- Mention key features\n",
    "- Keep response under {max_words} words\n",
    "- Use {tone} tone\n",
    "\n",
    "Answer:\n",
    "    \"\"\",\n",
    "    variables=[\"company\", \"product\", \"question\", \"max_words\", \"tone\"]\n",
    ")\n",
    "\n",
    "# Use the template\n",
    "prompt = product_template.format(\n",
    "    company=\"TechStore\",\n",
    "    product=\"iPhone 15 Pro\",\n",
    "    question=\"What's the battery life?\",\n",
    "    max_words=50,\n",
    "    tone=\"professional\"\n",
    ")\n",
    "\n",
    "print(\"Generated Prompt:\")\n",
    "print(prompt)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5B: Create Multiple Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template 1: Customer Service Response\n",
    "cs_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a customer service agent for {company}.\n",
    "\n",
    "Customer Issue: {issue}\n",
    "Customer Sentiment: {sentiment}\n",
    "\n",
    "Response Guidelines:\n",
    "- Acknowledge their {sentiment} feeling\n",
    "- Provide {solution_type}\n",
    "- Keep under {max_words} words\n",
    "- Use {tone} tone\n",
    "\n",
    "Your Response:\n",
    "    \"\"\",\n",
    "    variables=[\"company\", \"issue\", \"sentiment\", \"solution_type\",\n",
    "               \"max_words\", \"tone\"]\n",
    ")\n",
    "\n",
    "# Template 2: Email Classification\n",
    "email_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "Classify this customer email into categories: {categories}\n",
    "\n",
    "Email: {email_text}\n",
    "\n",
    "Classification Guidelines:\n",
    "- Primary category: Most relevant category\n",
    "- Urgency: {urgency_levels}\n",
    "- Confidence: 0-100%\n",
    "\n",
    "Return as JSON:\n",
    "{{\n",
    "  \"primary_category\": \"\",\n",
    "  \"urgency\": \"\",\n",
    "  \"confidence\": 0\n",
    "}}\n",
    "    \"\"\",\n",
    "    variables=[\"categories\", \"email_text\", \"urgency_levels\"]\n",
    ")\n",
    "\n",
    "# Test CS Template\n",
    "cs_prompt = cs_template.format(\n",
    "    company=\"TechStore\",\n",
    "    issue=\"Order delayed by 5 days\",\n",
    "    sentiment=\"frustrated\",\n",
    "    solution_type=\"explanation and resolution\",\n",
    "    max_words=75,\n",
    "    tone=\"empathetic\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": cs_prompt}],\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "print(\"Template Response:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5C: Your Turn - Create a Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a template for product recommendations\n",
    "#\n",
    "# Variables should include:\n",
    "# - customer_preferences\n",
    "# - budget_range\n",
    "# - product_category\n",
    "# - max_recommendations\n",
    "# - output_format\n",
    "\n",
    "recommendation_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "# Your template here\n",
    "    \"\"\",\n",
    "    variables=[]  # List your variables\n",
    ")\n",
    "\n",
    "# Test your template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ **Checkpoint**: Your template should be reusable and validate required inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Edge Case Handling (15 min)\n",
    "\n",
    "**Objective**: Build robust prompts that handle unexpected inputs.\n",
    "\n",
    "### Task 6A: Handle Empty/Unclear Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_unclear_input():\n",
    "    \"\"\"System message that handles unclear customer messages\"\"\"\n",
    "\n",
    "    system_message = \"\"\"\n",
    "You are a customer support assistant for TechStore.\n",
    "\n",
    "EDGE CASE HANDLING:\n",
    "\n",
    "If the message is empty, unclear, or lacks detail:\n",
    "- Do NOT make assumptions\n",
    "- Ask specific clarifying questions\n",
    "- Be polite and helpful\n",
    "\n",
    "Example:\n",
    "Customer: \"It doesn't work\"\n",
    "You: \"I'm here to help! To assist you better, could you tell me:\n",
    "1. Which product is having the issue?\n",
    "2. What specifically isn't working?\n",
    "3. What happens when you try to use it?\"\n",
    "\"\"\"\n",
    "\n",
    "    # Test with unclear inputs\n",
    "    unclear_messages = [\n",
    "        \"help\",\n",
    "        \"it's broken\",\n",
    "        \"???\",\n",
    "        \"need assistance\"\n",
    "    ]\n",
    "\n",
    "    for msg in unclear_messages:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": msg}\n",
    "            ],\n",
    "            max_tokens=150\n",
    "        )\n",
    "\n",
    "        print(f\"Customer: {msg}\")\n",
    "        print(f\"Assistant: {response.choices[0].message.content}\")\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "handle_unclear_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6B: Handle Out-of-Scope Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_out_of_scope():\n",
    "    \"\"\"Handle questions outside the bot's domain\"\"\"\n",
    "\n",
    "    system_message = \"\"\"\n",
    "You are a customer support assistant for TechStore (electronics retailer).\n",
    "\n",
    "SCOPE: You help with:\n",
    "- Product questions\n",
    "- Order tracking\n",
    "- Returns and warranty\n",
    "- Technical support\n",
    "\n",
    "OUT OF SCOPE: If asked about topics like politics, medical advice,\n",
    "personal counseling, or other unrelated topics:\n",
    "\n",
    "Response Template:\n",
    "\"I'm specialized in helping with TechStore products and orders. For\n",
    "{topic}, I'd recommend consulting {appropriate_resource}. How can I\n",
    "help you with your TechStore needs today?\"\n",
    "\"\"\"\n",
    "\n",
    "    out_of_scope_questions = [\n",
    "        \"What do you think about the upcoming election?\",\n",
    "        \"Can you give me medical advice for my headache?\",\n",
    "        \"What's the meaning of life?\",\n",
    "        \"Can you help me with my math homework?\"\n",
    "    ]\n",
    "\n",
    "    for question in out_of_scope_questions:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": question}\n",
    "            ],\n",
    "            max_tokens=100\n",
    "        )\n",
    "\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Response: {response.choices[0].message.content}\")\n",
    "        print()\n",
    "\n",
    "handle_out_of_scope()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6C: Handle Multiple Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_multiple_questions():\n",
    "    \"\"\"Handle customer messages with multiple questions\"\"\"\n",
    "\n",
    "    system_message = \"\"\"\n",
    "You are a customer support assistant.\n",
    "\n",
    "MULTIPLE QUESTIONS: If a customer asks multiple questions:\n",
    "\n",
    "Option 1: If related, address them in order\n",
    "Option 2: If unrelated, ask which is most urgent\n",
    "Option 3: Acknowledge all and address most critical first\n",
    "\n",
    "Always structure your response clearly with numbered points.\n",
    "\"\"\"\n",
    "\n",
    "    multi_question = \"\"\"\n",
    "I have several questions:\n",
    "1. Where is my order ORD-12345?\n",
    "2. Can I return an opened item?\n",
    "3. Do you sell laptops under $500?\n",
    "4. What's your warranty policy?\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": multi_question}\n",
    "        ],\n",
    "        max_tokens=250\n",
    "    )\n",
    "\n",
    "    print(\"Multiple Questions Test:\")\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "handle_multiple_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ **Checkpoint**: Bot should gracefully handle all edge cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Tone and Style Control (15 min)\n",
    "\n",
    "**Objective**: Master different communication tones for different situations.\n",
    "\n",
    "### Task 7A: Compare Tones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_different_tones():\n",
    "    \"\"\"Test same message with different tones\"\"\"\n",
    "\n",
    "    customer_message = \"My order is 3 days late!\"\n",
    "\n",
    "    tones = {\n",
    "        \"professional\": \"\"\"\n",
    "You are a professional customer service representative.\n",
    "Use formal language, proper grammar, and business-appropriate tone.\n",
    "        \"\"\",\n",
    "\n",
    "        \"friendly\": \"\"\"\n",
    "You are a warm, friendly customer service rep.\n",
    "Use contractions, casual language, and phrases like \"Happy to help!\"\n",
    "Be conversational but still professional.\n",
    "        \"\"\",\n",
    "\n",
    "        \"empathetic\": \"\"\"\n",
    "You are an empathetic customer service rep focused on emotional connection.\n",
    "Acknowledge frustrations, show genuine concern, use phrases like\n",
    "\"I understand how frustrating...\" and \"That must be disappointing...\"\n",
    "        \"\"\",\n",
    "\n",
    "        \"technical\": \"\"\"\n",
    "You are a precise, detail-oriented support specialist.\n",
    "Use clear, specific terminology. Provide exact procedures and systems.\n",
    "Focus on facts and processes.\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    print(f\"Customer: {customer_message}\\n\")\n",
    "\n",
    "    for tone_name, system_msg in tones.items():\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_msg},\n",
    "                {\"role\": \"user\", \"content\": customer_message}\n",
    "            ],\n",
    "            max_tokens=100\n",
    "        )\n",
    "\n",
    "        print(f\"=== {tone_name.upper()} TONE ===\")\n",
    "        print(response.choices[0].message.content)\n",
    "        print()\n",
    "\n",
    "test_different_tones()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7B: Choose Appropriate Tone\n",
    "\n",
    "**Scenario-Based Tone Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_tone_for_scenario(scenario, customer_message):\n",
    "    \"\"\"Choose appropriate tone based on scenario\"\"\"\n",
    "\n",
    "    tone_mapping = {\n",
    "        \"frustrated_customer\": \"empathetic\",\n",
    "        \"quick_question\": \"friendly\",\n",
    "        \"technical_issue\": \"technical\",\n",
    "        \"business_client\": \"professional\"\n",
    "    }\n",
    "\n",
    "    tone_prompts = {\n",
    "        \"empathetic\": \"Be understanding and compassionate. Acknowledge emotions.\",\n",
    "        \"friendly\": \"Be warm and approachable. Keep it light and helpful.\",\n",
    "        \"technical\": \"Be precise and detailed. Focus on step-by-step solutions.\",\n",
    "        \"professional\": \"Be formal and business-appropriate.\"\n",
    "    }\n",
    "\n",
    "    chosen_tone = tone_mapping.get(scenario, \"professional\")\n",
    "\n",
    "    system_message = f\"\"\"\n",
    "You are a customer support assistant.\n",
    "Tone: {tone_prompts[chosen_tone]}\n",
    "Keep responses under 75 words.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": customer_message}\n",
    "        ],\n",
    "        max_tokens=150\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test scenarios\n",
    "scenarios = [\n",
    "    (\"frustrated_customer\", \"This is the THIRD time my order was wrong!\"),\n",
    "    (\"quick_question\", \"What time do you close?\"),\n",
    "    (\"technical_issue\", \"Error code 0x8007045D when installing\"),\n",
    "    (\"business_client\", \"Please provide vendor specifications for procurement\")\n",
    "]\n",
    "\n",
    "for scenario, message in scenarios:\n",
    "    print(f\"Scenario: {scenario}\")\n",
    "    print(f\"Message: {message}\")\n",
    "    response = choose_tone_for_scenario(scenario, message)\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ **Checkpoint**: Each response should match the appropriate tone for the scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Capstone Project: SupportGenie v0.2 (30 min)\n",
    "\n",
    "**Objective**: Build an enhanced chatbot with all prompt engineering techniques.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "Your enhanced SupportGenie must:\n",
    "1. ‚úÖ Use a comprehensive system message\n",
    "2. ‚úÖ Include prompt templates for common scenarios\n",
    "3. ‚úÖ Handle edge cases gracefully\n",
    "4. ‚úÖ Adapt tone based on customer sentiment\n",
    "5. ‚úÖ Use few-shot examples for consistent formatting\n",
    "6. ‚úÖ Implement chain-of-thought for complex issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class SupportGenieV2:\n    \"\"\"\n    SupportGenie Version 0.2\n    Enhanced with advanced prompt engineering\n    \"\"\"\n\n    SYSTEM_MESSAGE = \"\"\"\nYou are SupportGenie, an expert AI customer support assistant for TechStore.\n\nIDENTITY & EXPERTISE:\n- Experienced customer service professional\n- Expert in TechStore products, policies, and procedures\n- Trained in empathetic communication\n- Solution-focused problem solver\n\nYOUR CAPABILITIES:\n‚úì Answer product questions\n‚úì Explain policies (returns, shipping, warranty)\n‚úì Troubleshoot common issues\n‚úì Track orders\n‚úì Create support tickets\n‚úì Escalate to human agents\n\nYOUR CONSTRAINTS:\n‚úó Never make up information\n‚úó Never share customer data\n‚úó Never engage with hostile behavior\n‚úó Never discuss topics outside TechStore support\n\nRESPONSE GUIDELINES:\n\n1. ACKNOWLEDGMENT (Always start here)\n   - Recognize the customer's concern\n   - Show empathy for their situation\n\n2. SOLUTION (Core of your response)\n   - Provide clear, actionable information\n   - Break down complex steps\n   - Cite relevant policies when applicable\n\n3. NEXT STEPS (Always end here)\n   - Ask if they need additional help\n   - Offer to escalate if needed\n\nTONE & STYLE:\n- Professional yet warm and approachable\n- Patient and understanding\n- Clear and concise (under 150 words)\n- Use customer's name if provided\n- Avoid jargon, explain technical terms\n\nEDGE CASE HANDLING:\n\nIf unclear:\n\"I want to make sure I help you with the right information. Could you\nclarify [specific detail]?\"\n\nIf out of scope:\n\"I specialize in TechStore products and support. For [topic], I'd\nrecommend [appropriate resource]. How else can I help with your\nTechStore needs?\"\n\nIf unable to resolve:\n\"I want to make sure you get the best help possible. Would you like\nme to escalate this to a specialized support agent?\"\n\nSENTIMENT AWARENESS:\n- If customer seems frustrated ‚Üí Lead with extra empathy\n- If urgent language (CAPS, \"!!!\") ‚Üí Acknowledge urgency\n- If confused ‚Üí Ask clarifying questions patiently\n- If satisfied ‚Üí Confirm resolution and offer future help\n    \"\"\"\n\n    # Prompt templates for common scenarios\n    TEMPLATES = {\n        \"order_tracking\": PromptTemplate(\n            template=\"\"\"\nCustomer is asking about order status.\n\nOrder Details:\n- Order Number: {order_number}\n- Status: {status}\n- Expected Delivery: {delivery_date}\n\nProvide a clear update with empathy and next steps.\n            \"\"\",\n            variables=[\"order_number\", \"status\", \"delivery_date\"]\n        ),\n\n        \"return_request\": PromptTemplate(\n            template=\"\"\"\nCustomer wants to return: {product}\nPurchase Date: {purchase_date}\nReason: {reason}\n\nOur policy: 30-day returns for unused items in original packaging.\n\nGuide them through the return process if eligible.\n            \"\"\",\n            variables=[\"product\", \"purchase_date\", \"reason\"]\n        ),\n\n        \"technical_support\": PromptTemplate(\n            template=\"\"\"\nCustomer has technical issue: {issue}\nProduct: {product}\n\nUse chain-of-thought troubleshooting:\n1. Identify likely causes\n2. Ask one diagnostic question\n3. Provide clear next step\n            \"\"\",\n            variables=[\"issue\", \"product\"]\n        )\n    }\n\n    def __init__(self, api_key):\n        self.client = OpenAI(api_key=api_key)\n        self.conversation_history = [\n            {\"role\": \"system\", \"content\": self.SYSTEM_MESSAGE}\n        ]\n\n    def detect_sentiment(self, message):\n        \"\"\"\n        Detect customer sentiment using few-shot learning\n        Returns: 'positive', 'negative', 'neutral', or 'urgent'\n        \"\"\"\n        prompt = f\"\"\"\nClassify the sentiment of the customer message. Use these examples:\n\nMessage: \"I love this product! Works perfectly!\" ‚Üí positive\nMessage: \"Thank you so much for your help!\" ‚Üí positive\nMessage: \"This is terrible! Product broke after 2 days!\" ‚Üí negative\nMessage: \"Very disappointed with the service\" ‚Üí negative\nMessage: \"WHERE IS MY ORDER?! I've been waiting 3 weeks!\" ‚Üí urgent\nMessage: \"NEED HELP NOW!!!\" ‚Üí urgent\nMessage: \"It's okay I guess\" ‚Üí neutral\nMessage: \"The item arrived. Thanks.\" ‚Üí neutral\n\nMessage: \"{message}\" ‚Üí\n\"\"\"\n\n        response = self.client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            max_tokens=10,\n            temperature=0.3\n        )\n\n        return response.choices[0].message.content.strip()\n\n    def detect_intent(self, message):\n        \"\"\"\n        Detect customer intent (order_tracking, return, technical_support, general)\n        \"\"\"\n        prompt = f\"\"\"\nClassify the intent of the customer message. Use these examples:\n\nMessage: \"Where is my order?\" ‚Üí order_tracking\nMessage: \"When will my package arrive?\" ‚Üí order_tracking\nMessage: \"Track order ORD-12345\" ‚Üí order_tracking\nMessage: \"I want to return this\" ‚Üí return\nMessage: \"Can I get a refund?\" ‚Üí return\nMessage: \"How do I send this back?\" ‚Üí return\nMessage: \"It won't turn on\" ‚Üí technical_support\nMessage: \"Device is not charging\" ‚Üí technical_support\nMessage: \"Error code 404\" ‚Üí technical_support\nMessage: \"What are your hours?\" ‚Üí general\nMessage: \"Do you sell laptops?\" ‚Üí general\nMessage: \"Tell me about your warranty\" ‚Üí general\n\nMessage: \"{message}\" ‚Üí\n\"\"\"\n\n        response = self.client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            max_tokens=20,\n            temperature=0.3\n        )\n\n        return response.choices[0].message.content.strip()\n\n    def chat(self, message, context=None):\n        \"\"\"\n        Enhanced chat with sentiment and intent detection\n\n        Args:\n            message: Customer's message\n            context: Optional dict with order info, product details, etc.\n        \"\"\"\n        # Detect sentiment and intent\n        sentiment = self.detect_sentiment(message)\n        intent = self.detect_intent(message)\n\n        print(f\"[Debug] Detected Sentiment: {sentiment}, Intent: {intent}\")\n\n        # Build enhanced message with context\n        if context:\n            enhanced_message = f\"\"\"\nCustomer Message: {message}\nDetected Sentiment: {sentiment}\nDetected Intent: {intent}\n\nAdditional Context:\n{context}\n            \"\"\"\n        else:\n            enhanced_message = f\"\"\"\nCustomer Message: {message}\nDetected Sentiment: {sentiment}\nDetected Intent: {intent}\n            \"\"\"\n\n        self.conversation_history.append({\n            \"role\": \"user\",\n            \"content\": enhanced_message\n        })\n\n        response = self.client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=self.conversation_history,\n            temperature=0.7,\n            max_tokens=500\n        )\n\n        assistant_message = response.choices[0].message.content\n\n        self.conversation_history.append({\n            \"role\": \"assistant\",\n            \"content\": assistant_message\n        })\n\n        return assistant_message\n\n    def reset(self):\n        \"\"\"Start a new conversation\"\"\"\n        self.conversation_history = [\n            {\"role\": \"system\", \"content\": self.SYSTEM_MESSAGE}\n        ]\n\n\n# Test your SupportGenie v0.2\ndef test_support_genie_v2():\n    \"\"\"Test the enhanced chatbot\"\"\"\n\n    api_key = os.getenv(\"OPENAI_API_KEY\")\n    bot = SupportGenieV2(api_key)\n\n    # Test Case 1: Frustrated customer with order issue\n    print(\"=\"*60)\n    print(\"TEST 1: Frustrated Customer\")\n    print(\"=\"*60)\n    response = bot.chat(\n        \"WHERE IS MY ORDER?! I ordered 2 weeks ago!\",\n        context=\"Order #ORD-12345, Status: In Transit, Expected: Tomorrow\"\n    )\n    print(f\"Bot: {response}\\n\")\n\n    # Test Case 2: Return request\n    print(\"=\"*60)\n    print(\"TEST 2: Return Request\")\n    print(\"=\"*60)\n    bot.reset()\n    response = bot.chat(\n        \"I'd like to return the laptop I bought last week\",\n        context=\"Product: Dell XPS 15, Purchase Date: 7 days ago, Condition: Unopened\"\n    )\n    print(f\"Bot: {response}\\n\")\n\n    # Test Case 3: Technical support\n    print(\"=\"*60)\n    print(\"TEST 3: Technical Issue\")\n    print(\"=\"*60)\n    bot.reset()\n    response = bot.chat(\n        \"My new headphones won't connect to my phone\",\n        context=\"Product: Sony WH-1000XM5, Purchased: Yesterday\"\n    )\n    print(f\"Bot: {response}\\n\")\n\n    # Test Case 4: Unclear input (edge case)\n    print(\"=\"*60)\n    print(\"TEST 4: Unclear Input (Edge Case)\")\n    print(\"=\"*60)\n    bot.reset()\n    response = bot.chat(\"help\")\n    print(f\"Bot: {response}\\n\")\n\n    # Test Case 5: Out of scope (edge case)\n    print(\"=\"*60)\n    print(\"TEST 5: Out of Scope (Edge Case)\")\n    print(\"=\"*60)\n    bot.reset()\n    response = bot.chat(\"What do you think about the economy?\")\n    print(f\"Bot: {response}\\n\")\n\n# Run the tests\ntest_support_genie_v2()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Tasks\n",
    "\n",
    "1. **Complete the sentiment detection** with more examples\n",
    "2. **Complete the intent detection** with more categories\n",
    "3. **Add at least 2 more test cases**\n",
    "4. **Customize the system message** for your use case\n",
    "5. **Add a new template** for a different scenario\n",
    "\n",
    "‚úÖ **Checkpoint**: Run all tests - bot should handle each scenario appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ Extension Challenges\n",
    "\n",
    "### Challenge 1: Multi-Language Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(message):\n",
    "    \"\"\"Detect message language and respond accordingly\"\"\"\n",
    "    # TODO: Implement language detection\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Conversation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_conversation(self):\n",
    "    \"\"\"Generate summary of conversation for ticket\"\"\"\n",
    "    # TODO: Create a summary of the entire conversation\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Response Quality Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_response(self, customer_msg, bot_response):\n",
    "    \"\"\"\n",
    "    Score response on:\n",
    "    - Empathy (1-5)\n",
    "    - Accuracy (1-5)\n",
    "    - Completeness (1-5)\n",
    "    \"\"\"\n",
    "    # TODO: Implement response scoring\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Key Takeaways\n",
    "\n",
    "After completing this lab, you should understand:\n",
    "\n",
    "‚úÖ **Specificity matters** - Vague prompts ‚Üí vague responses  \n",
    "‚úÖ **System messages control behavior** - Set the tone for entire conversations  \n",
    "‚úÖ **Examples improve consistency** - Few-shot learning ensures reliable formatting  \n",
    "‚úÖ **Templates improve maintainability** - Reusable prompts save time  \n",
    "‚úÖ **Edge cases must be handled** - Real users send unexpected inputs  \n",
    "‚úÖ **Tone matches the situation** - Adapt communication style to customer needs  \n",
    "‚úÖ **Chain-of-thought improves reasoning** - Step-by-step logic is more reliable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Troubleshooting\n",
    "\n",
    "**Issue**: Responses are too verbose\n",
    "\n",
    "**Solution**: Add explicit length constraints:\n",
    "```python\n",
    "\"Keep your response under 75 words.\"\n",
    "```\n",
    "\n",
    "**Issue**: Bot goes off-topic\n",
    "\n",
    "**Solution**: Strengthen system message constraints:\n",
    "```python\n",
    "\"You ONLY handle topics related to TechStore products and orders.\"\n",
    "```\n",
    "\n",
    "**Issue**: Inconsistent formatting\n",
    "\n",
    "**Solution**: Use few-shot examples with exact format:\n",
    "```python\n",
    "\"Return in this exact format: {...}\"\n",
    "```\n",
    "\n",
    "**Issue**: Bot makes up information\n",
    "\n",
    "**Solution**: Add strong constraints:\n",
    "```python\n",
    "\"If you don't know, say 'I don't have that information' and offer to escalate.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì What's Next?\n",
    "\n",
    "You've completed Lab 2! You now have:\n",
    "- ‚úÖ Deep understanding of prompt engineering\n",
    "- ‚úÖ Reusable prompt templates\n",
    "- ‚úÖ Enhanced SupportGenie v0.2\n",
    "\n",
    "**Next Lab**: Lab 3 - Document Processing & Embeddings  \n",
    "Learn how to give your bot access to a knowledge base!\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)\n",
    "- [Learn Prompting](https://learnprompting.org/)\n",
    "- [Anthropic Prompt Engineering](https://docs.anthropic.com/claude/docs/prompt-engineering)\n",
    "\n",
    "---\n",
    "\n",
    "**Lab 2 Complete!** üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
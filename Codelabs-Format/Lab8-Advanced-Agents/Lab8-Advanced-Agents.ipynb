{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Advanced Multi-Agent Systems\n",
    "\n",
    "**Duration**: 120-150 minutes  \n",
    "**Level**: Advanced  \n",
    "**Prerequisites**: Labs 6-7 completed\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this capstone lab, you'll build increasingly sophisticated multi-agent systems, culminating in a **production-ready intelligent research platform**.\n",
    "\n",
    "### What You'll Build:\n",
    "\n",
    "1. **Research Agent** - Autonomous information gathering system\n",
    "2. **Agentic RAG System** - Smart retrieval with decision-making\n",
    "3. **LangChain Agent** - Framework-powered agent\n",
    "4. **Multi-Agent System** - Collaborative agent team\n",
    "5. **ResearchHub v1.0** - Production multi-agent research platform (Capstone)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Build research agents that gather and synthesize information\n",
    "- Implement agentic RAG with dynamic retrieval\n",
    "- Use LangChain framework for rapid agent development\n",
    "- Create multi-agent systems with specialization\n",
    "- Implement agent-to-agent communication\n",
    "- Combine all concepts into production systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai anthropic python-dotenv\n",
    "!pip install chromadb sentence-transformers\n",
    "!pip install langchain langchain-openai langgraph\n",
    "!pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API keys\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "print(f\"OpenAI API Key present: {bool(openai_key)}\")\n",
    "print(f\"Anthropic API Key present: {bool(anthropic_key)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test setup\n",
    "from openai import OpenAI\n",
    "import chromadb\n",
    "\n",
    "# Test OpenAI\n",
    "try:\n",
    "    client = OpenAI(api_key=openai_key)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Hi\"}],\n",
    "        max_tokens=10\n",
    "    )\n",
    "    print(\"âœ“ OpenAI API working\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— OpenAI API error: {e}\")\n",
    "\n",
    "# Test ChromaDB\n",
    "try:\n",
    "    chroma_client = chromadb.Client()\n",
    "    print(\"âœ“ ChromaDB working\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— ChromaDB error: {e}\")\n",
    "\n",
    "# Test LangChain\n",
    "try:\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    print(\"âœ“ LangChain installed\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— LangChain error: {e}\")\n",
    "\n",
    "print(\"\\nâœ… Setup complete! Ready for exercises.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Research Agent\n",
    "\n",
    "Build an autonomous research agent that searches, retrieves, and synthesizes information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research Tools Implementation\n",
    "\n",
    "class ResearchTools:\n",
    "    \"\"\"Tools for research agent\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.search_history = []\n",
    "\n",
    "    def web_search(self, query: str, num_results: int = 3) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Simulated web search (in production, use real search API)\n",
    "        \"\"\"\n",
    "        print(f\"ðŸ” Searching: '{query}'\")\n",
    "\n",
    "        # Simulated knowledge base\n",
    "        knowledge = {\n",
    "            \"machine learning\": [\n",
    "                {\n",
    "                    \"title\": \"Machine Learning Fundamentals\",\n",
    "                    \"snippet\": \"ML enables systems to learn from data. Key types: supervised, unsupervised, and reinforcement learning.\",\n",
    "                    \"source\": \"ML Guide\"\n",
    "                },\n",
    "                {\n",
    "                    \"title\": \"ML Applications 2024\",\n",
    "                    \"snippet\": \"Modern ML powers healthcare diagnostics, autonomous vehicles, and recommendation systems.\",\n",
    "                    \"source\": \"Tech Review\"\n",
    "                }\n",
    "            ],\n",
    "            \"climate change\": [\n",
    "                {\n",
    "                    \"title\": \"Climate Science Consensus\",\n",
    "                    \"snippet\": \"97% of scientists agree climate change is human-caused, primarily through CO2 emissions.\",\n",
    "                    \"source\": \"IPCC\"\n",
    "                },\n",
    "                {\n",
    "                    \"title\": \"Climate Impact on Ecosystems\",\n",
    "                    \"snippet\": \"Rising temperatures affect biodiversity, oceans, and weather patterns globally.\",\n",
    "                    \"source\": \"Nature\"\n",
    "                }\n",
    "            ],\n",
    "            \"renewable energy\": [\n",
    "                {\n",
    "                    \"title\": \"Solar Power Advances\",\n",
    "                    \"snippet\": \"Solar efficiency reached 25% with perovskite materials, reducing costs significantly.\",\n",
    "                    \"source\": \"Energy Institute\"\n",
    "                },\n",
    "                {\n",
    "                    \"title\": \"Wind Energy Growth\",\n",
    "                    \"snippet\": \"Wind capacity grew 15% globally in 2023, with offshore wind leading expansion.\",\n",
    "                    \"source\": \"Renewable News\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # Find matching results\n",
    "        query_lower = query.lower()\n",
    "        results = []\n",
    "\n",
    "        for key, articles in knowledge.items():\n",
    "            if key in query_lower or any(word in query_lower for word in key.split()):\n",
    "                results.extend(articles[:num_results])\n",
    "\n",
    "        if not results:\n",
    "            results = [{\n",
    "                \"title\": f\"General info about {query}\",\n",
    "                \"snippet\": \"Information available from various sources.\",\n",
    "                \"source\": \"Web\"\n",
    "            }]\n",
    "\n",
    "        result_data = {\n",
    "            \"query\": query,\n",
    "            \"num_results\": len(results[:num_results]),\n",
    "            \"results\": results[:num_results],\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "        self.search_history.append(result_data)\n",
    "        return result_data\n",
    "\n",
    "print(\"ResearchTools class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research Agent Implementation\n",
    "\n",
    "class ResearchAgent:\n",
    "    \"\"\"Autonomous research agent\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.tools = ResearchTools()\n",
    "        self.findings = []\n",
    "\n",
    "        self.tool_definitions = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"web_search\",\n",
    "                    \"description\": \"Search the web for information. Returns relevant articles.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"query\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Search query\"\n",
    "                            },\n",
    "                            \"num_results\": {\n",
    "                                \"type\": \"integer\",\n",
    "                                \"description\": \"Number of results (default: 3)\",\n",
    "                                \"default\": 3\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"query\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        self.functions = {\n",
    "            \"web_search\": self.tools.web_search\n",
    "        }\n",
    "\n",
    "    def research(self, topic: str, depth: str = \"moderate\") -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Conduct research on a topic\n",
    "\n",
    "        Args:\n",
    "            topic: Research topic\n",
    "            depth: \"brief\", \"moderate\", or \"comprehensive\"\n",
    "\n",
    "        Returns:\n",
    "            Research report\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"RESEARCH AGENT: {topic}\")\n",
    "        print('='*70)\n",
    "\n",
    "        # Determine iterations based on depth\n",
    "        max_iterations = {\"brief\": 3, \"moderate\": 5, \"comprehensive\": 8}[depth]\n",
    "\n",
    "        system_prompt = f\"\"\"You are an expert research agent. Your task is to research this topic: {topic}\n",
    "\n",
    "Guidelines:\n",
    "1. Search for information using web_search tool\n",
    "2. Gather diverse perspectives\n",
    "3. Identify key facts and insights\n",
    "4. Track sources\n",
    "5. Synthesize findings into a coherent report\n",
    "\n",
    "For {depth} research, make {max_iterations} iterations maximum.\"\"\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Research this topic: {topic}\"}\n",
    "        ]\n",
    "\n",
    "        iteration = 0\n",
    "\n",
    "        while iteration < max_iterations:\n",
    "            iteration += 1\n",
    "            print(f\"\\n--- Research Iteration {iteration} ---\")\n",
    "\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=messages,\n",
    "                tools=self.tool_definitions,\n",
    "                tool_choice=\"auto\"\n",
    "            )\n",
    "\n",
    "            response_message = response.choices[0].message\n",
    "\n",
    "            # Check if done\n",
    "            if not response_message.tool_calls:\n",
    "                final_report = response_message.content\n",
    "\n",
    "                print(f\"\\n{'='*70}\")\n",
    "                print(\"âœ… RESEARCH COMPLETE\")\n",
    "                print('='*70)\n",
    "                print(final_report)\n",
    "\n",
    "                return {\n",
    "                    \"topic\": topic,\n",
    "                    \"report\": final_report,\n",
    "                    \"searches_performed\": len(self.tools.search_history),\n",
    "                    \"iterations\": iteration\n",
    "                }\n",
    "\n",
    "            # Execute tool calls\n",
    "            messages.append(response_message)\n",
    "\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                print(f\"\\nðŸ”§ {function_name}({json.dumps(arguments)})\")\n",
    "\n",
    "                # Execute\n",
    "                result = self.functions[function_name](**arguments)\n",
    "\n",
    "                print(f\"   Found {result['num_results']} results\")\n",
    "\n",
    "                # Add to messages\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": json.dumps(result)\n",
    "                })\n",
    "\n",
    "        return {\n",
    "            \"topic\": topic,\n",
    "            \"report\": \"Research incomplete - max iterations reached\",\n",
    "            \"searches_performed\": len(self.tools.search_history)\n",
    "        }\n",
    "\n",
    "print(\"ResearchAgent class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Research Agent\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESEARCH AGENT DEMONSTRATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "agent = ResearchAgent()\n",
    "\n",
    "# Test 1: Brief research\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"TEST 1: Brief Research\")\n",
    "print(\"#\"*70)\n",
    "result = agent.research(\"machine learning applications\", depth=\"brief\")\n",
    "print(f\"\\nSearches performed: {result['searches_performed']}\")\n",
    "\n",
    "# Test 2: Moderate research\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"TEST 2: Moderate Research\")\n",
    "print(\"#\"*70)\n",
    "agent2 = ResearchAgent()\n",
    "result = agent2.research(\"renewable energy trends\", depth=\"moderate\")\n",
    "print(f\"\\nSearches performed: {result['searches_performed']}\")\n",
    "\n",
    "print(\"\\nâœ… Exercise 1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Checkpoint 1\n",
    "\n",
    "**What you learned:**\n",
    "- Research agent architecture\n",
    "- Multi-step information gathering\n",
    "- Result synthesis and reporting\n",
    "- Dynamic search strategies\n",
    "\n",
    "**Key Insight**: Research agents can autonomously gather information from multiple sources and synthesize coherent reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Agentic RAG System\n",
    "\n",
    "Build a RAG system where the **agent decides when and what to retrieve**.\n",
    "\n",
    "This is different from traditional RAG where retrieval always happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge Base Setup for Agentic RAG\n",
    "\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class KnowledgeBase:\n",
    "    \"\"\"Vector database for Agentic RAG\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.chroma_client = chromadb.PersistentClient(path=\"./agentic_rag_db\")\n",
    "        self.embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "        self.collection = self.chroma_client.get_or_create_collection(\n",
    "            name=\"agentic_rag_docs\"\n",
    "        )\n",
    "\n",
    "        # Populate if empty\n",
    "        if self.collection.count() == 0:\n",
    "            self._populate()\n",
    "\n",
    "    def _populate(self):\n",
    "        \"\"\"Populate with sample documents\"\"\"\n",
    "        documents = [\n",
    "            {\n",
    "                \"text\": \"Machine learning is a subset of AI that enables systems to learn from data without explicit programming. Key types include supervised, unsupervised, and reinforcement learning.\",\n",
    "                \"metadata\": {\"topic\": \"machine_learning\", \"category\": \"basics\"}\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Deep learning uses neural networks with multiple layers to automatically learn hierarchical representations. It excels at tasks like image recognition and natural language processing.\",\n",
    "                \"metadata\": {\"topic\": \"deep_learning\", \"category\": \"advanced\"}\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Supervised learning trains models on labeled data, learning to map inputs to outputs. Common applications include classification and regression tasks.\",\n",
    "                \"metadata\": {\"topic\": \"supervised_learning\", \"category\": \"techniques\"}\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Unsupervised learning discovers patterns in unlabeled data through techniques like clustering and dimensionality reduction.\",\n",
    "                \"metadata\": {\"topic\": \"unsupervised_learning\", \"category\": \"techniques\"}\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Natural language processing enables computers to understand and generate human language. Applications include translation, sentiment analysis, and chatbots.\",\n",
    "                \"metadata\": {\"topic\": \"nlp\", \"category\": \"applications\"}\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        for i, doc in enumerate(documents):\n",
    "            embedding = self.embedding_model.encode(doc[\"text\"])\n",
    "            self.collection.add(\n",
    "                documents=[doc[\"text\"]],\n",
    "                embeddings=[embedding.tolist()],\n",
    "                ids=[f\"doc_{i}\"],\n",
    "                metadatas=[doc[\"metadata\"]]\n",
    "            )\n",
    "\n",
    "        print(f\"âœ“ Knowledge base populated with {len(documents)} documents\")\n",
    "\n",
    "print(\"KnowledgeBase class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agentic RAG Implementation\n",
    "\n",
    "class AgenticRAG:\n",
    "    \"\"\"RAG system where agent decides when to retrieve\"\"\"\n",
    "\n",
    "    def __init__(self, knowledge_base: KnowledgeBase):\n",
    "        self.kb = knowledge_base\n",
    "        self.embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        self.retrieval_log = []\n",
    "\n",
    "        self.tools = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"retrieve_documents\",\n",
    "                    \"description\": \"Retrieve relevant documents from the knowledge base. Use ONLY when you need specific information you don't know.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"query\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Search query for documents\"\n",
    "                            },\n",
    "                            \"n_results\": {\n",
    "                                \"type\": \"integer\",\n",
    "                                \"description\": \"Number of documents to retrieve (default: 2)\",\n",
    "                                \"default\": 2\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"query\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        self.functions = {\n",
    "            \"retrieve_documents\": self.retrieve_documents\n",
    "        }\n",
    "\n",
    "    def retrieve_documents(self, query: str, n_results: int = 2) -> Dict:\n",
    "        \"\"\"Retrieve documents from knowledge base\"\"\"\n",
    "        print(f\"\\nðŸ“š Retrieving: '{query}'\")\n",
    "\n",
    "        query_embedding = self.embedding_model.encode(query)\n",
    "\n",
    "        results = self.kb.collection.query(\n",
    "            query_embeddings=[query_embedding.tolist()],\n",
    "            n_results=n_results,\n",
    "            include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "        )\n",
    "\n",
    "        documents = []\n",
    "        for i in range(len(results['documents'][0])):\n",
    "            doc = {\n",
    "                \"content\": results['documents'][0][i],\n",
    "                \"metadata\": results['metadatas'][0][i],\n",
    "                \"relevance\": 1 / (1 + results['distances'][0][i])\n",
    "            }\n",
    "            documents.append(doc)\n",
    "            print(f\"   [{i+1}] {doc['metadata'].get('topic')} (relevance: {doc['relevance']:.3f})\")\n",
    "\n",
    "        self.retrieval_log.append({\n",
    "            \"query\": query,\n",
    "            \"num_docs\": len(documents)\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"query\": query,\n",
    "            \"documents\": documents,\n",
    "            \"count\": len(documents)\n",
    "        }\n",
    "\n",
    "    def answer_question(self, question: str) -> Dict:\n",
    "        \"\"\"Answer question using agentic RAG\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"AGENTIC RAG\")\n",
    "        print('='*70)\n",
    "        print(f\"Question: {question}\\n\")\n",
    "\n",
    "        system_prompt = \"\"\"You are an intelligent assistant with access to a knowledge base about machine learning and AI.\n",
    "\n",
    "CRITICAL INSTRUCTIONS:\n",
    "- If you already know the answer from general knowledge, answer directly WITHOUT retrieving\n",
    "- ONLY use retrieve_documents when you need specific information from the knowledge base\n",
    "- You can retrieve multiple times if needed\n",
    "- Think step-by-step about whether retrieval is necessary\n",
    "\n",
    "Examples:\n",
    "- \"What is 2+2?\" â†’ NO retrieval needed, answer directly\n",
    "- \"What is machine learning?\" â†’ Could answer from general knowledge OR retrieve for specifics\n",
    "- \"According to the knowledge base, what is deep learning?\" â†’ MUST retrieve\"\"\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "\n",
    "        iteration = 0\n",
    "        max_iterations = 5\n",
    "\n",
    "        while iteration < max_iterations:\n",
    "            iteration += 1\n",
    "            print(f\"--- Iteration {iteration} ---\")\n",
    "\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=messages,\n",
    "                tools=self.tools,\n",
    "                tool_choice=\"auto\"\n",
    "            )\n",
    "\n",
    "            response_message = response.choices[0].message\n",
    "\n",
    "            # Check if done\n",
    "            if not response_message.tool_calls:\n",
    "                answer = response_message.content\n",
    "\n",
    "                print(f\"\\n{'='*70}\")\n",
    "                print(\"âœ… ANSWER:\")\n",
    "                print('='*70)\n",
    "                print(answer)\n",
    "\n",
    "                return {\n",
    "                    \"question\": question,\n",
    "                    \"answer\": answer,\n",
    "                    \"retrievals\": len(self.retrieval_log),\n",
    "                    \"retrieval_log\": self.retrieval_log\n",
    "                }\n",
    "\n",
    "            # Show agent reasoning\n",
    "            if response_message.content:\n",
    "                print(f\"\\nðŸ’­ Agent: {response_message.content}\")\n",
    "\n",
    "            messages.append(response_message)\n",
    "\n",
    "            # Execute retrievals\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                result = self.functions[function_name](**arguments)\n",
    "\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": json.dumps(result)\n",
    "                })\n",
    "\n",
    "        return {\"question\": question, \"answer\": \"Max iterations reached\"}\n",
    "\n",
    "print(\"AgenticRAG class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Agentic RAG\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"AGENTIC RAG DEMONSTRATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "kb = KnowledgeBase()\n",
    "agentic_rag = AgenticRAG(kb)\n",
    "\n",
    "# Test 1: General knowledge (should NOT retrieve)\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"TEST 1: General Knowledge (No Retrieval Expected)\")\n",
    "print(\"#\"*70)\n",
    "result = agentic_rag.answer_question(\"What is 25 * 4?\")\n",
    "print(f\"\\nRetrievals: {result['retrievals']} (expected: 0)\")\n",
    "\n",
    "# Test 2: KB-specific question (SHOULD retrieve)\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"TEST 2: Knowledge Base Query (Retrieval Expected)\")\n",
    "print(\"#\"*70)\n",
    "agentic_rag.retrieval_log = []  # Reset log\n",
    "result = agentic_rag.answer_question(\"According to the knowledge base, what is supervised learning?\")\n",
    "print(f\"\\nRetrievals: {result['retrievals']} (expected: 1+)\")\n",
    "\n",
    "# Test 3: Multi-hop question (MULTIPLE retrievals)\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"TEST 3: Multi-Hop Query (Multiple Retrievals Expected)\")\n",
    "print(\"#\"*70)\n",
    "agentic_rag.retrieval_log = []\n",
    "result = agentic_rag.answer_question(\"Compare machine learning and deep learning based on the knowledge base\")\n",
    "print(f\"\\nRetrievals: {result['retrievals']} (expected: 2+)\")\n",
    "\n",
    "print(\"\\nâœ… Exercise 2 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Checkpoint 2\n",
    "\n",
    "**What you learned:**\n",
    "- Agentic RAG decision-making\n",
    "- Dynamic retrieval strategies\n",
    "- Multi-hop reasoning\n",
    "- Retrieval vs general knowledge\n",
    "\n",
    "**Key Difference**: Traditional RAG always retrieves. Agentic RAG **decides** when retrieval is needed, making it more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: LangChain Framework Agent\n",
    "\n",
    "Build agents using the **LangChain framework** for rapid development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# LangChain Agent with Tools\n\nfrom langchain_openai import ChatOpenAI\nfrom langchain.agents import AgentExecutor, create_tool_calling_agent\nfrom langchain_core.tools import tool\nfrom langchain_core.prompts import ChatPromptTemplate\nimport ast\nimport operator\n\ndef safe_eval_math(expression: str) -> float:\n    \"\"\"Safely evaluate mathematical expressions without using eval()\"\"\"\n    # Define allowed operators\n    operators_map = {\n        ast.Add: operator.add,\n        ast.Sub: operator.sub,\n        ast.Mult: operator.mul,\n        ast.Div: operator.truediv,\n        ast.Pow: operator.pow,\n        ast.USub: operator.neg,\n    }\n    \n    def eval_node(node):\n        if isinstance(node, ast.Num):  # number\n            return node.n\n        elif isinstance(node, ast.BinOp):  # binary operation\n            return operators_map[type(node.op)](eval_node(node.left), eval_node(node.right))\n        elif isinstance(node, ast.UnaryOp):  # unary operation\n            return operators_map[type(node.op)](eval_node(node.operand))\n        else:\n            raise ValueError(f\"Unsupported operation: {type(node)}\")\n    \n    try:\n        tree = ast.parse(expression, mode='eval')\n        return eval_node(tree.body)\n    except Exception as e:\n        raise ValueError(f\"Invalid mathematical expression: {str(e)}\")\n\n@tool\ndef calculator(expression: str) -> str:\n    \"\"\"Perform mathematical calculations. Input should be a math expression like '25 * 4'.\"\"\"\n    try:\n        result = safe_eval_math(expression)\n        return f\"Result: {result}\"\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n@tool\ndef text_analyzer(text: str) -> str:\n    \"\"\"Analyze text and return statistics: word count, character count, sentence count.\"\"\"\n    words = len(text.split())\n    chars = len(text)\n    sentences = text.count('.') + text.count('!') + text.count('?')\n\n    return f\"\"\"Text Analysis:\nâ€¢ Words: {words}\nâ€¢ Characters: {chars}\nâ€¢ Sentences: {sentences}\nâ€¢ Avg word length: {chars/words:.1f} chars\"\"\"\n\n@tool\ndef knowledge_search(query: str) -> str:\n    \"\"\"Search knowledge base for information on AI and ML topics.\"\"\"\n    knowledge = {\n        \"langchain\": \"LangChain is a framework for developing LLM-powered applications.\",\n        \"agents\": \"Agents are autonomous systems that use LLMs to reason and act.\",\n        \"rag\": \"RAG combines LLMs with external knowledge retrieval.\",\n        \"tools\": \"Tools extend agent capabilities with functions and APIs.\"\n    }\n\n    query_lower = query.lower()\n    for key, value in knowledge.items():\n        if key in query_lower:\n            return f\"**{key.title()}**: {value}\"\n\n    return \"No information found.\"\n\nprint(\"LangChain tools defined!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LangChain Agent\n",
    "\n",
    "def create_langchain_agent():\n",
    "    \"\"\"Create a LangChain agent with tools\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CREATING LANGCHAIN AGENT\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Initialize LLM\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    # Define tools\n",
    "    tools = [calculator, text_analyzer, knowledge_search]\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant with access to tools. Use them when appropriate.\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ])\n",
    "\n",
    "    # Create agent\n",
    "    agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "    # Create executor\n",
    "    executor = AgentExecutor(\n",
    "        agent=agent,\n",
    "        tools=tools,\n",
    "        verbose=True,\n",
    "        max_iterations=10,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "\n",
    "    print(\"âœ“ Agent created with tools: calculator, text_analyzer, knowledge_search\")\n",
    "\n",
    "    return executor\n",
    "\n",
    "print(\"create_langchain_agent function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test LangChain Agent\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LANGCHAIN AGENT DEMONSTRATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "agent = create_langchain_agent()\n",
    "\n",
    "# Test 1: Calculator\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"TEST 1: Calculator\")\n",
    "print(\"#\"*70)\n",
    "result = agent.invoke({\"input\": \"What is 15% of 340?\"})\n",
    "print(f\"\\nâœ… Answer: {result['output']}\")\n",
    "\n",
    "# Test 2: Text Analysis\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"TEST 2: Text Analysis\")\n",
    "print(\"#\"*70)\n",
    "result = agent.invoke({\n",
    "    \"input\": \"Analyze this text: 'LangChain makes building AI agents easy and powerful. It provides tools for rapid development.'\"\n",
    "})\n",
    "print(f\"\\nâœ… Answer: {result['output']}\")\n",
    "\n",
    "# Test 3: Knowledge Search\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"TEST 3: Knowledge Search\")\n",
    "print(\"#\"*70)\n",
    "result = agent.invoke({\"input\": \"What is RAG?\"})\n",
    "print(f\"\\nâœ… Answer: {result['output']}\")\n",
    "\n",
    "print(\"\\nâœ… Exercise 3 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Checkpoint 3\n",
    "\n",
    "**What you learned:**\n",
    "- LangChain framework basics\n",
    "- Tool decorator (@tool)\n",
    "- AgentExecutor usage\n",
    "- Rapid agent development\n",
    "\n",
    "**Key Benefit**: LangChain provides high-level abstractions that simplify agent development compared to building from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Multi-Agent System\n",
    "\n",
    "Build a collaborative multi-agent system with **specialized agents** working together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Agent System Implementation\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "class BaseAgent:\n",
    "    \"\"\"Base class for all agents\"\"\"\n",
    "\n",
    "    def __init__(self, name: str, role: str, temperature: float = 0):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=temperature)\n",
    "\n",
    "    def execute(self, task: str) -> str:\n",
    "        \"\"\"Execute a task\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "class ResearcherAgent(BaseAgent):\n",
    "    \"\"\"Agent specialized in research\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Researcher\",\n",
    "            role=\"conducting research and gathering information\",\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "    def execute(self, task: str) -> str:\n",
    "        \"\"\"Research a topic\"\"\"\n",
    "        print(f\"\\nðŸ”¬ {self.name} researching...\")\n",
    "\n",
    "        prompt = f\"\"\"You are a research specialist. Research this topic and provide 3-4 key findings: {task}\n",
    "\n",
    "Focus on facts, insights, and important information.\"\"\"\n",
    "\n",
    "        response = self.llm.invoke([\n",
    "            SystemMessage(content=f\"You are an expert at {self.role}.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ])\n",
    "\n",
    "        return response.content\n",
    "\n",
    "class AnalystAgent(BaseAgent):\n",
    "    \"\"\"Agent specialized in analysis\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Analyst\",\n",
    "            role=\"analyzing information and identifying patterns\",\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "    def execute(self, task: str) -> str:\n",
    "        \"\"\"Analyze information\"\"\"\n",
    "        print(f\"\\nðŸ“Š {self.name} analyzing...\")\n",
    "\n",
    "        prompt = f\"\"\"You are an analysis specialist. Analyze this information and provide insights: {task}\n",
    "\n",
    "Identify patterns, trends, and important takeaways.\"\"\"\n",
    "\n",
    "        response = self.llm.invoke([\n",
    "            SystemMessage(content=f\"You are an expert at {self.role}.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ])\n",
    "\n",
    "        return response.content\n",
    "\n",
    "class WriterAgent(BaseAgent):\n",
    "    \"\"\"Agent specialized in writing\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Writer\",\n",
    "            role=\"creating clear, engaging content\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "    def execute(self, task: str) -> str:\n",
    "        \"\"\"Write content\"\"\"\n",
    "        print(f\"\\nâœï¸  {self.name} writing...\")\n",
    "\n",
    "        prompt = f\"\"\"You are a professional writer. Create content based on this: {task}\n",
    "\n",
    "Write clearly and engagingly in 2-3 paragraphs.\"\"\"\n",
    "\n",
    "        response = self.llm.invoke([\n",
    "            SystemMessage(content=f\"You are an expert at {self.role}.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ])\n",
    "\n",
    "        return response.content\n",
    "\n",
    "print(\"Specialized agent classes defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinator Agent\n",
    "\n",
    "class CoordinatorAgent(BaseAgent):\n",
    "    \"\"\"Coordinates multiple specialist agents\"\"\"\n",
    "\n",
    "    def __init__(self, agents: Dict[str, BaseAgent]):\n",
    "        super().__init__(\n",
    "            name=\"Coordinator\",\n",
    "            role=\"coordinating team of specialist agents\",\n",
    "            temperature=0\n",
    "        )\n",
    "        self.agents = agents\n",
    "\n",
    "    def delegate(self, task: str) -> Dict[str, str]:\n",
    "        \"\"\"Determine which agents to use and delegate\"\"\"\n",
    "        print(f\"\\nðŸ‘” {self.name} analyzing task...\")\n",
    "\n",
    "        available_agents = \", \".join(self.agents.keys())\n",
    "\n",
    "        prompt = f\"\"\"Task: {task}\n",
    "\n",
    "Available specialist agents: {available_agents}\n",
    "\n",
    "Which agent(s) should handle this task? Consider:\n",
    "- researcher: for finding information\n",
    "- analyst: for analyzing data/information\n",
    "- writer: for creating written content\n",
    "\n",
    "Respond with ONLY the agent name(s), comma-separated.\"\"\"\n",
    "\n",
    "        response = self.llm.invoke([\n",
    "            SystemMessage(content=\"You are a task coordinator.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ])\n",
    "\n",
    "        # Parse assigned agents\n",
    "        assigned = [a.strip().lower() for a in response.content.split(',')]\n",
    "        assigned = [a for a in assigned if a in self.agents]\n",
    "\n",
    "        print(f\"   Assigned to: {', '.join(assigned)}\")\n",
    "\n",
    "        # Execute with assigned agents\n",
    "        results = {}\n",
    "        for agent_name in assigned:\n",
    "            agent = self.agents[agent_name]\n",
    "            result = agent.execute(task)\n",
    "            results[agent_name] = result\n",
    "\n",
    "        return results\n",
    "\n",
    "    def synthesize(self, task: str, results: Dict[str, str]) -> str:\n",
    "        \"\"\"Synthesize results from multiple agents\"\"\"\n",
    "        print(f\"\\nðŸ‘” {self.name} synthesizing results...\")\n",
    "\n",
    "        results_text = \"\\n\\n\".join([\n",
    "            f\"**{name.title()}**: {result}\"\n",
    "            for name, result in results.items()\n",
    "        ])\n",
    "\n",
    "        prompt = f\"\"\"Original task: {task}\n",
    "\n",
    "Results from specialist agents:\n",
    "{results_text}\n",
    "\n",
    "Synthesize these results into a cohesive final answer.\"\"\"\n",
    "\n",
    "        response = self.llm.invoke([\n",
    "            SystemMessage(content=\"You are an expert at synthesis.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ])\n",
    "\n",
    "        return response.content\n",
    "\n",
    "print(\"CoordinatorAgent class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Multi-Agent System\n",
    "\n",
    "class MultiAgentSystem:\n",
    "    \"\"\"Complete multi-agent system\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Create specialist agents\n",
    "        self.agents = {\n",
    "            \"researcher\": ResearcherAgent(),\n",
    "            \"analyst\": AnalystAgent(),\n",
    "            \"writer\": WriterAgent()\n",
    "        }\n",
    "\n",
    "        # Create coordinator\n",
    "        self.coordinator = CoordinatorAgent(self.agents)\n",
    "\n",
    "    def execute_task(self, task: str) -> str:\n",
    "        \"\"\"Execute task using multi-agent system\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"MULTI-AGENT SYSTEM\")\n",
    "        print('='*70)\n",
    "        print(f\"Task: {task}\")\n",
    "        print('='*70)\n",
    "\n",
    "        # Delegate to agents\n",
    "        results = self.coordinator.delegate(task)\n",
    "\n",
    "        # Synthesize\n",
    "        final_result = self.coordinator.synthesize(task, results)\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"âœ… FINAL RESULT:\")\n",
    "        print('='*70)\n",
    "        print(final_result)\n",
    "\n",
    "        return final_result\n",
    "\n",
    "print(\"MultiAgentSystem class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Multi-Agent System\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MULTI-AGENT SYSTEM DEMONSTRATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "system = MultiAgentSystem()\n",
    "\n",
    "# Test: Research + Analysis + Writing\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"TEST: Complete Workflow (Research â†’ Analyze â†’ Write)\")\n",
    "print(\"#\"*70)\n",
    "system.execute_task(\n",
    "    \"Research the benefits of multi-agent AI systems, analyze the key advantages, \"\n",
    "    \"and write a brief summary\"\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Exercise 4 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Checkpoint 4\n",
    "\n",
    "**What you learned:**\n",
    "- Multi-agent architectures\n",
    "- Specialized agent roles\n",
    "- Coordinator pattern\n",
    "- Agent-to-agent collaboration\n",
    "\n",
    "**Key Pattern**: Coordinator agent routes tasks to specialists, then synthesizes their outputs into final results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Project: ResearchHub v1.0\n",
    "\n",
    "Build a **production-ready research platform** combining:\n",
    "- Research agents\n",
    "- Agentic RAG\n",
    "- Multi-agent collaboration\n",
    "- Advanced workflows\n",
    "\n",
    "This is your **final capstone project** bringing together all 8 labs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResearchHub v1.0 - Production Research Platform\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ResearchHub:\n",
    "    \"\"\"\n",
    "    Production multi-agent research platform combining:\n",
    "    - Research agents\n",
    "    - Agentic RAG\n",
    "    - Multi-agent collaboration\n",
    "    - Advanced workflows\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"ResearchHub v1.0\"\n",
    "\n",
    "        # Initialize knowledge base\n",
    "        self.kb = self._setup_knowledge_base()\n",
    "\n",
    "        # Initialize tools\n",
    "        self.tools = self._setup_tools()\n",
    "        self.functions = self._setup_functions()\n",
    "\n",
    "        # Research history\n",
    "        self.research_history = []\n",
    "\n",
    "        logger.info(f\"{self.name} initialized\")\n",
    "\n",
    "    def _setup_knowledge_base(self):\n",
    "        \"\"\"Setup vector database\"\"\"\n",
    "        chroma_client = chromadb.PersistentClient(path=\"./researchhub_db\")\n",
    "        embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "        collection = chroma_client.get_or_create_collection(name=\"research_docs\")\n",
    "\n",
    "        # Populate if empty\n",
    "        if collection.count() == 0:\n",
    "            docs = [\n",
    "                \"AI agents are autonomous systems that can reason, plan, and take actions using tools.\",\n",
    "                \"Multi-agent systems involve multiple specialized agents collaborating on complex tasks.\",\n",
    "                \"LangChain is a framework for building LLM-powered applications with agents and tools.\",\n",
    "                \"Agentic RAG systems use agents to decide when and what to retrieve from knowledge bases.\",\n",
    "                \"Research agents can autonomously gather, analyze, and synthesize information from multiple sources.\"\n",
    "            ]\n",
    "\n",
    "            for i, doc in enumerate(docs):\n",
    "                embedding = embedding_model.encode(doc)\n",
    "                collection.add(\n",
    "                    documents=[doc],\n",
    "                    embeddings=[embedding.tolist()],\n",
    "                    ids=[f\"doc_{i}\"]\n",
    "                )\n",
    "\n",
    "        logger.info(f\"Knowledge base ready with {collection.count()} documents\")\n",
    "\n",
    "        return {\"collection\": collection, \"model\": embedding_model}\n",
    "\n",
    "    def _setup_tools(self):\n",
    "        \"\"\"Setup tool definitions\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"web_search\",\n",
    "                    \"description\": \"Search the web for information on a topic\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"query\": {\"type\": \"string\", \"description\": \"Search query\"},\n",
    "                            \"num_results\": {\"type\": \"integer\", \"default\": 3}\n",
    "                        },\n",
    "                        \"required\": [\"query\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"retrieve_documents\",\n",
    "                    \"description\": \"Retrieve documents from knowledge base\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"query\": {\"type\": \"string\", \"description\": \"Search query\"},\n",
    "                            \"n_results\": {\"type\": \"integer\", \"default\": 2}\n",
    "                        },\n",
    "                        \"required\": [\"query\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"analyze_findings\",\n",
    "                    \"description\": \"Analyze research findings to identify key insights\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"findings\": {\"type\": \"string\", \"description\": \"Research findings to analyze\"}\n",
    "                        },\n",
    "                        \"required\": [\"findings\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def _setup_functions(self):\n",
    "        \"\"\"Setup function implementations\"\"\"\n",
    "        return {\n",
    "            \"web_search\": self.web_search,\n",
    "            \"retrieve_documents\": self.retrieve_documents,\n",
    "            \"analyze_findings\": self.analyze_findings\n",
    "        }\n",
    "\n",
    "    def web_search(self, query: str, num_results: int = 3) -> Dict:\n",
    "        \"\"\"Simulated web search\"\"\"\n",
    "        logger.info(f\"Web search: {query}\")\n",
    "\n",
    "        knowledge = {\n",
    "            \"agents\": [\"AI agents use LLMs for reasoning\", \"Agents can use tools autonomously\"],\n",
    "            \"langchain\": [\"LangChain simplifies agent development\", \"LangChain provides pre-built patterns\"],\n",
    "            \"rag\": [\"RAG retrieves relevant context\", \"Agentic RAG adds decision-making\"]\n",
    "        }\n",
    "\n",
    "        results = []\n",
    "        for key, snippets in knowledge.items():\n",
    "            if key in query.lower():\n",
    "                results.extend([{\"snippet\": s, \"source\": \"Web\"} for s in snippets])\n",
    "\n",
    "        return {\"success\": True, \"query\": query, \"results\": results[:num_results]}\n",
    "\n",
    "    def retrieve_documents(self, query: str, n_results: int = 2) -> Dict:\n",
    "        \"\"\"Retrieve from knowledge base\"\"\"\n",
    "        logger.info(f\"KB retrieval: {query}\")\n",
    "\n",
    "        query_embedding = self.kb[\"model\"].encode(query)\n",
    "\n",
    "        results = self.kb[\"collection\"].query(\n",
    "            query_embeddings=[query_embedding.tolist()],\n",
    "            n_results=n_results,\n",
    "            include=[\"documents\"]\n",
    "        )\n",
    "\n",
    "        docs = [{\"content\": doc} for doc in results['documents'][0]]\n",
    "\n",
    "        return {\"success\": True, \"query\": query, \"documents\": docs}\n",
    "\n",
    "    def analyze_findings(self, findings: str) -> Dict:\n",
    "        \"\"\"Analyze research findings\"\"\"\n",
    "        logger.info(\"Analyzing findings...\")\n",
    "\n",
    "        # Simple analysis (in production, use LLM)\n",
    "        insights = [\n",
    "            \"Key patterns identified\",\n",
    "            \"Important themes extracted\",\n",
    "            \"Conclusions drawn\"\n",
    "        ]\n",
    "\n",
    "        return {\"success\": True, \"insights\": insights}\n",
    "\n",
    "    def conduct_research(self, topic: str, mode: str = \"comprehensive\") -> Dict:\n",
    "        \"\"\"\n",
    "        Conduct comprehensive research\n",
    "\n",
    "        Args:\n",
    "            topic: Research topic\n",
    "            mode: \"quick\", \"standard\", or \"comprehensive\"\n",
    "\n",
    "        Returns:\n",
    "            Research report\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ðŸ¢ {self.name} - RESEARCH MODE: {mode.upper()}\")\n",
    "        print('='*70)\n",
    "        print(f\"Topic: {topic}\\n\")\n",
    "\n",
    "        max_iterations = {\"quick\": 3, \"standard\": 5, \"comprehensive\": 8}[mode]\n",
    "\n",
    "        system_prompt = f\"\"\"You are ResearchHub, an advanced research platform.\n",
    "\n",
    "Your capabilities:\n",
    "- web_search: Search for information\n",
    "- retrieve_documents: Query knowledge base\n",
    "- analyze_findings: Analyze research results\n",
    "\n",
    "Conduct {mode} research on: {topic}\n",
    "\n",
    "Process:\n",
    "1. Search and retrieve information\n",
    "2. Analyze findings\n",
    "3. Synthesize comprehensive report\"\"\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Research: {topic}\"}\n",
    "        ]\n",
    "\n",
    "        iteration = 0\n",
    "\n",
    "        while iteration < max_iterations:\n",
    "            iteration += 1\n",
    "            print(f\"--- Iteration {iteration} ---\")\n",
    "\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=messages,\n",
    "                tools=self.tools,\n",
    "                tool_choice=\"auto\"\n",
    "            )\n",
    "\n",
    "            response_message = response.choices[0].message\n",
    "\n",
    "            if not response_message.tool_calls:\n",
    "                report = response_message.content\n",
    "\n",
    "                print(f\"\\n{'='*70}\")\n",
    "                print(\"âœ… RESEARCH COMPLETE\")\n",
    "                print('='*70)\n",
    "                print(report)\n",
    "\n",
    "                result = {\n",
    "                    \"topic\": topic,\n",
    "                    \"mode\": mode,\n",
    "                    \"report\": report,\n",
    "                    \"iterations\": iteration,\n",
    "                    \"timestamp\": datetime.now().isoformat()\n",
    "                }\n",
    "\n",
    "                self.research_history.append(result)\n",
    "\n",
    "                return result\n",
    "\n",
    "            messages.append(response_message)\n",
    "\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                print(f\"\\nðŸ”§ {function_name}({list(arguments.keys())})\")\n",
    "\n",
    "                result = self.functions[function_name](**arguments)\n",
    "\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": json.dumps(result)\n",
    "                })\n",
    "\n",
    "        return {\"error\": \"Max iterations reached\"}\n",
    "\n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"Get platform statistics\"\"\"\n",
    "        return {\n",
    "            \"total_research_conducted\": len(self.research_history),\n",
    "            \"kb_documents\": self.kb[\"collection\"].count(),\n",
    "            \"tools_available\": len(self.tools)\n",
    "        }\n",
    "\n",
    "print(\"ResearchHub v1.0 class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate ResearchHub\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ¢ RESEARCHHUB v1.0 - PRODUCTION RESEARCH PLATFORM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "hub = ResearchHub()\n",
    "\n",
    "# Research tasks\n",
    "tasks = [\n",
    "    (\"Multi-agent AI systems\", \"quick\"),\n",
    "    (\"Agentic RAG vs traditional RAG\", \"standard\")\n",
    "]\n",
    "\n",
    "for i, (topic, mode) in enumerate(tasks, 1):\n",
    "    print(f\"\\n{'#'*70}\")\n",
    "    print(f\"RESEARCH TASK {i}/{len(tasks)}\")\n",
    "    print('#'*70)\n",
    "\n",
    "    hub.conduct_research(topic, mode=mode)\n",
    "\n",
    "# Show stats\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ðŸ“Š PLATFORM STATISTICS\")\n",
    "print('='*70)\n",
    "stats = hub.get_stats()\n",
    "for key, value in stats.items():\n",
    "    print(f\"  â€¢ {key.replace('_', ' ').title()}: {value}\")\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Lab Complete!\n",
    "\n",
    "Congratulations! You've completed all 8 labs of the Advanced GenAI Training!\n",
    "\n",
    "### What You Accomplished:\n",
    "\n",
    "1. **Research Agent** - Autonomous information gathering\n",
    "2. **Agentic RAG** - Smart retrieval with decision-making\n",
    "3. **LangChain Agent** - Framework-powered development\n",
    "4. **Multi-Agent System** - Collaborative specialists\n",
    "5. **ResearchHub v1.0** - Production research platform\n",
    "\n",
    "### Skills Mastered Across All 8 Labs:\n",
    "\n",
    "**Labs 1-2: Foundations**\n",
    "- LLM fundamentals and API usage\n",
    "- Prompt engineering techniques\n",
    "- System messages and few-shot learning\n",
    "\n",
    "**Labs 3-5: RAG Systems**\n",
    "- Document processing and chunking\n",
    "- Vector embeddings and semantic search\n",
    "- Complete RAG pipeline development\n",
    "\n",
    "**Labs 6-7: Agents**\n",
    "- Tool calling and function execution\n",
    "- Agent memory systems\n",
    "- ReAct framework and planning\n",
    "- Self-reflection and adaptation\n",
    "\n",
    "**Lab 8: Advanced Systems**\n",
    "- Research agent architectures\n",
    "- Agentic RAG vs traditional RAG\n",
    "- LangChain framework usage\n",
    "- Multi-agent coordination\n",
    "- Production deployment patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Challenges\n",
    "\n",
    "### Challenge 1: Add More Agents\n",
    "Extend the multi-agent system with:\n",
    "- CriticAgent (reviews and critiques)\n",
    "- EditorAgent (edits and improves content)\n",
    "- FactCheckerAgent (validates information)\n",
    "\n",
    "### Challenge 2: Advanced RAG\n",
    "Enhance agentic RAG with:\n",
    "- Query reformulation\n",
    "- Source ranking\n",
    "- Contradiction detection\n",
    "- Citation tracking\n",
    "\n",
    "### Challenge 3: LangGraph Workflow\n",
    "Build a LangGraph workflow with:\n",
    "- Conditional routing\n",
    "- Parallel processing\n",
    "- State management\n",
    "- Error recovery\n",
    "\n",
    "### Challenge 4: Production Deployment\n",
    "Deploy ResearchHub with:\n",
    "- API endpoints (FastAPI)\n",
    "- User authentication\n",
    "- Rate limiting\n",
    "- Monitoring and logging\n",
    "- Cost tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "**You've completed the Advanced GenAI Training!** ðŸŽ‰\n",
    "\n",
    "### Continue Your Journey:\n",
    "\n",
    "1. **Build Real-World Projects**\n",
    "   - Personal research assistant\n",
    "   - Customer support automation\n",
    "   - Content generation pipeline\n",
    "   - Data analysis agent\n",
    "\n",
    "2. **Deploy to Production**\n",
    "   - Cloud deployment (AWS, GCP, Azure)\n",
    "   - Containerization (Docker)\n",
    "   - Orchestration (Kubernetes)\n",
    "   - Monitoring (Prometheus, Grafana)\n",
    "\n",
    "3. **Contribute to Open Source**\n",
    "   - LangChain\n",
    "   - LlamaIndex\n",
    "   - AutoGen\n",
    "   - CrewAI\n",
    "\n",
    "4. **Keep Learning**\n",
    "   - Advanced agent frameworks\n",
    "   - Multi-modal AI\n",
    "   - Agent safety and alignment\n",
    "   - Scaling production systems\n",
    "\n",
    "**Ready to build the future with AI agents!** ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}